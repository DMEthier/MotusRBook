# Accessing and understanding detections data {#accessingData}

The success of the Motus network is dependent on the timely upload of detection data from receivers, and on the maintenance of accurate and up to date tag and receiver metadata by collaborators. After downloading your data from the Motus server, users are encouraged to check for updated detection data and metadata each time they run an analysis, because collaborators can add detection data and metadata at any time, and these could influence the completeness of your own detections data.

## Database types {#databaseTypes}

```{r fig3, echo = FALSE}

knitr::include_graphics("images/DataStructure.png")

```

<br>

There are two types of tag databases:

1. **receiver database**: includes all detections of any registered tags from a single receiver. A receiver database has a name like SG-1234BBBK5678.motus; where the name is the serial number of the receiver.

2. **project database**: includes all detections of your registered tags from across the motus network. A tag project database has a name like project-123.motus, where the number is the motus project ID.


These two databases correspond to the basic model of data sharing:

1. you get all detections of anyone's tags by *your* receivers (i.e., one receiver tag database for each receiver you deploy)

2. you get all detections of *your* tags by *anyone's* receivers (i.e., one project tag database for each of your motus projects)

## Load relevant R packages {#loadPackages}

```{r loadPackages, warning = FALSE, message = FALSE}

require(devtools)
require(tidyverse)
require(lubridate)

```

## Importing tag detections {#importDetections}

To import tag detections for your project or receiver, you need a numerical project id or character scalar receiver serial number. 

### Download data for a project or receiver for the _first time_

When downloading data from the Motus server for the first time, you must specify update = TRUE and new = TRUE. Unless the directory that you want your data saved in is stated explicitly within the function call, data will be downloaded to the current working directory:

```{r tagme1, eval = FALSE}

getwd() # to see what the current working directory is. 

# use setwd() if you want to change the working directory.
t <- tagme(projRecv = 123, update = TRUE, new = TRUE)                 # for project tag database OR:
t <- tagme(projRecv = "SG-1013BB000626", update = TRUE, new = TRUE)  # for receiver tag database
```

Or specify a directory to create and open a local tag database using "dir = ":

```{r tagme2, eval = FALSE, message = FALSE, warning = FALSE}

t <- tagme(projRecv = 123, update = TRUE, new = TRUE, dir = "./data/") 

```

This will write a copy of your tag database to the working or specified folder, stored as an SQLite file with the extension '.motus'. 

### Update and open a local tag database

To open and update a detections database that already exists (has been downloaded previously):

```{r tagme2, eval = FALSE}

t <- tagme(projRecv = 123) ## if the file is in the local working directory, OR:
t <- tagme(projRecv = 123, dir = "./data/") ## use dir = to specify a directory

```

### Force an update/re-import of tag and receiver deployment metadata

Tag and receiver metadata are automatically merged with tag detections when data are downloaded. However, if you want to force a re-import of the metadata when updating a database, you can run:  

```{r tagme5, eval = FALSE}

t <- tagme(projRecv = 123, forceMeta = TRUE)

```

### Check if new data are available

To check if new data are available without downloading the data, you can use the tellme() function, which returns a list with:

- **numBatches**: number of batches of new data. 
- **numRuns**: number of runs of new tag detections, where a run is a series of continuous detections for a tag on a given antenna.
- **numHits**: number of new tag detections.
- **size**: approximate uncompressed size of data transfer required, in megabytes.

The following assumes that a local copy of the database already exists:

```{r tagme4b, eval = FALSE}

tellme(projRecv = 123)                    ## If db is in the working directory
tellme(projRecv = 123, dir = "C/Data/")   ## To specify a different directory

```

To check how much data is available for a project but you _do not_ have a database for it, use the 'new' parameter:

```{r tagme4c, eval = FALSE}

tellme(projRecv = 123, new = TRUE)

```

## Data structure {#databaseStructure}

Each tag database is stored as an SQLite ('dplyr::src_sqlite') file with the extension '.motus'. The sqlite format was chosen because:

1. it is flexible, allowing for many data formats.
2. it is accessible from many software platforms (not just R).
3. it is **appendable**: the database can be created and updated on disk without having to read in and resave the entire contents. This will save time and computer memory when searching to see if any new detections are available for your project or receiver.

The .motus file contains a series of interelated tables where data are stored in a condensed format to save memory. The following tables are included in the .motus file; a complete list of parameters stored in each table can be found in Appendix Table A1:

1. hits: detection data at the level of individual hits.
2. runs: detection data associated with a run (continuous detections of a unique tag on a given receiver).
3. batches: detection data for a given receiver and boot number.
4. batchRuns:
5. projBatch:
5. meta:
6. tags: metadata related to tags, e.g., unique identifier, tag characteristics (e.g., burst interval).
7. tagAmbig
8. tagDeps: metadata related to tag deployments, e.g., deployment date, location, and species.
9. recvs:
10. recvDeps: metadata related to receiver deployments, e.g., deployment date, location, receiver characteristics.
11. antDeps: metadata related to antenna deployments, e.g., deployment height, angle, antenna type.
12. species: metadata related to species, e.g., unique identifier, scientific name, common name.
13. projs: metadata related to projects, e.g., project name, principal investigator.
14. gps: metadata related to Geographic Positioning System (GPS) position of receiver. 
15. projAmbig: 

In addition to these tables, there are also 'virtual' tables, which are queries that merge data from the various tables into a single convenient 'view' that contains all of the fields you are likely to need. The following views are currently included in each .motus file:

1. alltags
2. allambigs
3. alltagswithambigs

Because the file is a dplyr::src_sqlite file, all of the dplyr functions can be used to filter and summarize the .motus database, without needing to first save the data as a *flat* file, i.e., a typical two-dimensional dataframe with every record for each field filled in. 

Each table in the .motus file can be accessed using the tbl() function, for example:

```{r getTable, eval = FALSE}

# tag deployment metadata
tagMeta <- tbl(t, "tagDeps")
head(tagMeta)           
tagMeta$ops$vars        # list the variable names in the table

```

The underlying structure of these tables shows that each is a list of length 2:

```{r dfStructure, eval = FALSE}

str(tagMeta)

```

The first part of the list, 'src', is a list that provides details of the SQLiteConnection, including where the database is stored. The second part is a list that includes the names of the variables ('tagMeta$ops$vars') included in the  table. Thus, the R object 'tagMeta' is a *virtual* table that stores the database structure and information required to connect to the underlying data in the .motus file. As stated above, the advantage of storing the data in this way is that it saves memory when accessing very large databases, and the dplyr package can be used to manipulate and summarize the tables before collecting the results into a typical "flat" format dataframe.

The *virtual* table 'alltagswithambigs' contains all fields that most users will need from the various .motus tables, and can also be accessed using the dplyr tbl() function:  

```{r getAllTagsTable, eval = FALSE}

df <- tbl(t, "alltagswithambigs")

```

The following table lists the parameters available in the 'alltagswithambigs' view, along with a description of each parameter.

```{r parameterTable, echo = FALSE}

param.table <- dplyr::select(read.csv("./data/DatabaseParameters.csv"), 1:2)
knitr::kable(param.table, caption = "Description of fields in the tag detections database") 

```

## Convert a SQLITE table to a flat dataframe {#convertToFlat}

To convert the 'alltagswithambigs' view or other table into a typical 'flat' format, i.e., with every record for each field filled in, use the collect() function.  The output can then be used to generate a RDS file of your data. We suggest using RDS instead of CSV, because the RDS format provides many advantages, including saving the environment (e.g., time zone), which means date/times don't need to be manipulated each time a file is loaded. However, if you simply want to download and export your data for use in another program, CSV format might be preferred.

We caution that producing a flat file using the full suite of fields can chew up a lot of memory, and can slow R down considerably when dealing with large datasets:

```{r collect, eval = FALSE}

df.flat <- df %>% 
  collect() %>% 
  as.data.frame()      ## for all fields in the df

```

```{r quickLook, eval = FALSE}

names(df.flat)     ## field names
str(df.flat)       ## Look at the structure of your data fields
head(df.flat)      ## Look at first 6 rows of your df
summary(df.flat)   ## summary of each column in your df

```

If you want to load only part of your entire data frame (e.g. certain fields, certain tags, or all tags from a specified project or species), you can use dplyr funtions to filter the data before collecting into a flat dataframe.  Some examples are below:

1. To select certain fields:

```{r collect1, eval = FALSE}

## to grab a subset of fields, in this case a unique list of motus tag IDs 
## at each receiver and antenna.
df.flat.subset <- select(df, recv, ant, motusTagID) %>%
  distinct() %>% 
  collect() %>% 
  as.data.frame()     

```

2. To select certain tag IDs:

```{r collect2, eval = FALSE}

df.flat.subset <- filter(df, motusTagID %in% c(16011, 23316)) %>%  ## filter to include only motusTagIDs 9939, 25643
                  collect() %>% 
                  as.data.frame()   

```

3. To select a specified species:

```{r collect3, eval = FALSE}

df.flat.subset <- filter(df, speciesID == 4670) %>%  ## filter to only Red Knot (using speciesID)
  collect() %>% 
  as.data.frame()   

df.flat.subset <- filter(df, spEN == "Red Knot") %>%   ## filter to only Red Knot (using English name)
  collect() %>% 
  as.data.frame()  

```

Using dplyr(), data can also be summarized before converting to a flat file. For example, to find the maximum signal strength of each tag in each hour by receiver:

```{r collectSum, eval = FALSE}

df.hourlySumm <- df %>% 
          mutate (hour = 3600 * round(ts / 3600, 0)) %>% 
          group_by(motusTagID, recv, hour) %>%
          summarize(
            max.sig = max(sig)) %>%
          collect() %>%
          as.data.frame()

```

## Export your 'flat' dataframe to CSV or RDS file {#exportDetections}

A good workflow idea is to have a script that deals with all of your data issues, then saves a dataframe (or workspace) for re-use. If you do this, you can quickly start an analysis or visualization session from a known (and consistent) starting point. When working in R, a good way to do this is by using an RDS file, which preserves all of the associated R data structures (such as time stamps).

```{r createRDS, eval = FALSE, message = FALSE, warning = FALSE}

## save an RDS file
saveRDS(df.flat, "./data/df.flat.RDS")  

## or save as CSV file, which does not preserve time stamps, but is more universally accepted

write.csv(df.flat, "./data/df.flat.CSV", row.names = FALSE)

```

### Create function to output .motus tables to 'flat' dataframes {#flatRDSfunction}

For the purpose of this book, the following function creates flat CSV or RDS files of the various tables that we will need from the .motus file. You can run this function on your own data as it is, or modify it to include/exclude different fields in the various tables. 
In this function, we include some basic data filters, create date and location variables, and select the variables that are likely to be of interest and use for most applications. This includes:

1. creating 'recvLat' and 'recvLon' variables, which default to using the latitude and longitude derived from the GPS in each receiver, and in-fills missing GPS values with the latitude and longitude from the receiver deployment metadata entered online by the project that deployed the station.

2. creating an 'ambig' variable, which assigns a '1' when the detections could belong to two or more (up to 6) duplicate tags.

3. providing filters for run length and standard deviation of frequency offset among pulses in a burst, which can give an indication of the probability that a detection is a false positive. Generally, detections with runLen <= 2 have a high probability of being false positive, as do detections with freqSD > 0.1  kHz. These filters are included, but not used here (see Chapter \@ref(dataCleaning)).

```{r dataFunction}

# for your own data, replace with location of your 'project-XX.motus' data

createFlatFiles <- function(out.dir, in.df, table.list, output.format) {  

  # load .motus file

  file.name <-  in.df 
  t <- dplyr::src_sqlite(file.name)

  # Loop through table.list, create flat file, and save to RDS file
  # An if() statement is included to select only certain parameters from the alltagswithambigs table
  # This can be modified to include different parameters, or to create a different if() statement for
  # another table.
  
  for(i in 1:length(table.list)) {
    
        df <- tbl(t, table.list[i])
       
        if(table.list[i] == "alltagswithambigs"){
        df <- mutate(df,  # create receiver Lat/Lon fields- use lat/lon from GPS, and if NA, use the lat/lon from the receiver deployment metadata
                     recvLat = if_else(is.na(gpsLat), recvDeployLat, gpsLat), 
                     recvLon = if_else(is.na(gpsLon), recvDeployLon, gpsLon),
                     # create an ambiguous column, so detections are labelled as ambiguous or not
                     ambig = if_else(is.na(ambigID), 0, 1))  %>% 
              # keep only parameters of interest. Could potentially drop gpsLat/Lon and recvDeployLat/Lon
              select(hitID, runID, batchID, ts, sig, sigsd, freqsd, motusTagID, ambigID, ant, 
                     runLen, tagProjID, tagDeployID, id, depLat, depLon, depAlt, recvDeployID, recvDeployLat,
                     recvDeployLon, recvDeployElevation, recv, site, projID, antType, antBearing, antHeight, 
                     spEN, spFR, spSci, tagProj, proj, gpsLat, gpsLon, gpsAlt, recvLat, recvLon, ambig) %>%
              # keep only run lengths greater than 2. This can be modified later, to see if any detections with
              # a run length of two are real detections.
          
              filter(runLen >=2) # note we are inlcuding 2 here; add: ", freqSD <= 0.1" to filter for freqSD as well.
          

        } # end of if statement
    
                           
   
        df <- df %>% 
              collect() %>% 
              as.data.frame()
  
        # once in a flat file, modify timestamp which is stored in the .motus file as seconds since Jan 01, 1970
        
        if(table.list[i] == "alltagswithambigs"){
            df <- mutate(df, 
                  ts = as_datetime(ts, tz = "GMT", origin = "1970-01-01"))
        } # end of if statement
        
        # modify times of tag and receiver deployment metadata
        
        if(table.list[i] == "tagDeps"|table.list[i] == "recvDeps"){
            df <- mutate(df, 
                  tsStart = as_datetime(tsStart, tz = "GMT", origin = "1970-01-01"), 
                  tsEnd = as_datetime(tsEnd, tz = "GMT", origin = "1970-01-01"))
        } # end of if statement
        
  if(output.format == "RDS") {     
  saveRDS(df, file = paste(out.dir, "df.", table.list[i], ".rds", sep = "")) 
  }
  
  if(output.format == "CSV") {     
  write.csv(df, file = paste(out.dir, "df.", table.list[i], ".csv", sep = ""), row.names = FALSE) 
  }     
     
  } # end of for loop
} # end of function
```

Run the function by first setting the parameters 'out.dir', 'in.df', and 'table.list':

```{r runDataRDSFunction, eval = FALSE}

# choose output format, choice of RDS or CSV:

output.format <- "RDS"

# directory where you want your flat RDS files to be stored 
out.dir <- paste(getwd(), "/data/", sep = "") # or change to the output directory of your choice

# full location of your .motus file. This will typically look like in.df <- "C:/Motus/data/project-xx.motus"
in.df <- system.file("extdata", "project-sample.motus", package = "motusdata") 

# list of tables in your .motus file that you want to transform to flat files:
table.list <- c("alltagswithambigs", "tags", "tagDeps", "recvs", "recvDeps", "antDeps", "species")

# run the function, which will output an RDS flat file for each table in the specified directory
createFlatFiles(out.dir = out.dir, in.df = in.df, table.list = table.list, output.format = output.format)

```

### Access the book sample dataset

For the purposes of this book, the sample data from the James Bay Shorebird Project (see Section \@ref(sampleData)) has been downloaded and the .motus and RDS files made available through the motusdata R package. You can use the following code to load the sample data:

```{r importSampleData, message = FALSE}

## to access the .motus file for the sample data contained in the motusdata package:

file.name <- system.file("extdata", "project-sample.motus", package = "motusdata") 
t <- dplyr::src_sqlite(file.name)

## to access the RDS tables:

** FILL THIS IN

```
