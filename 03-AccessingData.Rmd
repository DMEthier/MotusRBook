# Accessing and understanding detections data {#accessingData}

```{r fig3, echo = FALSE}

knitr::include_graphics("images/DataStructure.png")

```

<br>

## Database types {#databaseTypes}

There are two types of tag databases:

1. **receiver database**: includes all detections of any registered tags from a single receiver. A receiver database has a name like SG-1234BBBK5678.motus; where the name is the serial number of the receiver.

2. **project database**: includes all detections of your registered tags from across the motus network. A tag project database has a name like project-123.motus, where the number is the motus project ID.

These two databases correspond to the basic model of data sharing:

1. you get all detections of anyone's tags by *your* receivers (i.e., one receiver tag database for each receiver you deploy)

2. you get all detections of *your* tags by *anyone's* receivers (i.e., one project tag database for each of your motus projects)


## Load relevant R packages {#loadPackages}

Before we begin working with data, we need to load the required packages. If you have not yet installed these packages (from github and CRAN) then please return to Chapter \@ref(loadingPackages) and do so.

```{r loadPackages, warning = FALSE, message = FALSE}

## these function calls will only install updated packages
require(devtools)

## required 'motus' package from github
require(motus)

## required other packages from CRAN.
require(tidyverse)
require(lubridate)

```

## Set system environment

Set the system environment time zone to Greenwich Mean Time (GMT), to ensure that you are always working in GMT. This is a very important step, and should be part of every working session. If you fail to do this, then two problems can arise. Times are stored in the motus database in GMT, and if you do not keep your environment in GMT, then they can be inadvertently changed during import. Second if tags have been detected across multiple time zones, then they can also inadvertently be changed.

```{r setTimeZone }

Sys.setenv(TZ="GMT")

```

## Importing tag detections {#importDetections}

To import tag detections for your project or receiver, you need a numerical project id or character scalar receiver serial number. 

The success of the Motus network is dependent on the timely upload of detection data from receivers, and on the maintenance of accurate and up to date tag and receiver metadata by collaborators. After downloading your data from the Motus server, users are encouraged to check for updated detection data and metadata each time they run an analysis, because collaborators can add detection data and metadata at any time, and these could influence the completeness of your own detections data.

### Download data for a project or receiver for the _first time_

When downloading data from the Motus server for the first time, you must specify update = TRUE and new = TRUE. Unless the directory that you want your data saved in is stated explicitly within the function call, data will be downloaded to the current working directory. 

### User Authentication {#userAuthentication}

Note that the first time you call a function using the Motus R package, you will be asked for your motus.org username and password to authenticate your access to project data. This will only happen once per R session. If you do not have a Motus user name and password, you can sign up at <https://motus.org/data/user/new>. Permission to access project data will then be granted by Motus staff or the project principal investigator.

Throughout this book we will use sample data which has been assigned to project 176.  When accessing this data you will need to login as follows:

user name: motus.sample
password: motus.sample

### Logging out {#logout}

Once you are logged in under one user account, you will not be able to access data from another account.  If you need to logout of the current account to access other data, you can run the code below.

```{r logout, eval = FALSE}

motusLogout()

```

Let's get started. Note that there are no receivers registered to sample project 176, so the second call (by receiver) will not find any data. You can, however, replace the receiver serial number with one registered to your project if you are logged in under your own credentials (ie. not motus.sample account, see \@ref(logout)). 

Be warned that large datasets can take some time to download from the Motus server when downloading for the first time ('new = TRUE' in the tagme function call). The sample dataset, for example, can take upwards of 3 hours to download completely. 

In the event that your connection to the Motus server fails prior to the download completing (e.g., due to poor internet connection), use `r tagme(proj.num. update = TRUE), eval = FALSE` to continue the download from where it left off, ensuring to specify a directory if it's saved outside the working directory.  

After the initial download, loading a .motus file into R using `r tagme(proj.num, new = FALSE), eval = FALSE` will be near instantaneous.

```{r tagme1, eval = FALSE}

getwd()         ## to see the current working directory; use setwd() to change it.
proj.num <- 176 ## 176 for the sample data, or use the number associated with your project here

sql.motus <- tagme(projRecv = proj.num, update = TRUE, new = TRUE)     # for project tag database
sql.motus <- tagme(projRecv = "SG-123BBBK1234", update = TRUE, new = TRUE)           # for receiver tag database

```

If you don't want to use the working directory, specify a directory to create and open a local tag database using "dir = ":

```{r tagme2, eval = FALSE, message = FALSE, warning = FALSE}

sql.motus <- tagme(projRecv = proj.num, update = TRUE, new = TRUE, dir = "./data/") 

```

The tagme() function will write a copy of your tag database to the working or specified folder, stored as an SQLite file with the extension '.motus'. 

### Update and open a local tag database

To open and update a detections database that already exists (has been downloaded previously):

```{r tagme3, eval = FALSE}

sql.motus <- tagme(projRecv = proj.num, new = FALSE, update = TRUE, dir = "./data/") ## use dir = to specify a directory

```

### Force an update/re-import of tag and receiver deployment metadata

Tag and receiver metadata are automatically merged with tag detections when data are downloaded. However, if you want to force a re-import of the metadata when updating a database, you can run:  

```{r tagme4, eval = FALSE}

sql.motus <- tagme(projRecv = proj.num, forceMeta = TRUE)

```

### Check if new data are available

To check if new data are available without downloading the data, you can use the tellme() function, which returns a list with:

- **numBatches**: number of batches of new data. 
- **numRuns**: number of runs of new tag detections, where a run is a series of continuous detections for a tag on a given antenna.
- **numHits**: number of new tag detections.
- **size**: approximate uncompressed size of data transfer required, in megabytes.

The following assumes that a local copy of the database already exists:

```{r tagme5, eval = FALSE}

tellme(projRecv = proj.num)                    ## If db is in the working directory
tellme(projRecv = proj.num, dir = "./data/")   ## To specify a different directory

```

To check how much data is available for a project but you _do not_ have a database for it, use the 'new' parameter:

```{r tagme6, eval = FALSE}

tellme(projRecv = proj.num, new = TRUE)

```

## Data structure {#databaseStructure}

Each tag database is stored as an SQLite ('dplyr::src_sqlite') file with the extension '.motus'. The sqlite format was chosen because:

1. it is flexible, allowing for many data formats.
2. it is accessible from many software platforms (not just R).
3. it is **appendable**: the database can be created and updated on disk without having to read in and resave the entire contents. This will save time and computer memory when searching to see if any new detections are available for your project or receiver.

The .motus file contains a series of interelated tables where data are stored in a condensed format to save memory. The following tables are included in the .motus file; a complete list of variables stored in each table can be found in \@ref(appendixA):

1. antDeps: metadata related to antenna deployments, e.g., deployment height, angle, antenna type.
2. batches: detection data for a given receiver and boot number.
3. batchRuns: metadata for runIDs and associated batchIDs
4. clarified: 
5. filters:
6. gps: metadata related to Geographic Positioning System (GPS) position of receiver. 
7. hits: detection data at the level of individual hits.
8. meta: metadata related to the project and datatype (tags vs. receiveres) that are included in the .motus file
9. projAmbig: metadata related to what projects have ambiguous tag detections
10. projBatch: metadata for the number of detections contained in each batch
11. projs: metadata related to projects, e.g., project name, principal investigator.
12. recvDeps: metadata related to receiver deployments, e.g., deployment date, location, receiver characteristics.
13. recvs: metadata related to receiver serial number and associated Motus deviceID
14. runs: detection data associated with a run (continuous detections of a unique tag on a given receiver).
15. runsFilters: 
16. species: metadata related to species, e.g., unique identifier, scientific name, common name.
17. tagAmbig: metadata related to ambiguous tags, e.g., ambigID and associated motusTagID
18. tagDeps: metadata related to tag deployments, e.g., deployment date, location, and species.
19. tags: metadata related to tags, e.g., unique identifier, tag characteristics (e.g., burst interval).

In addition to these tables, there are also 'virtual' tables or 'views', which are queries that merge data from the various tables into a single convenient 'view' that contains all of the fields you are likely to need. The following views are currently included in each .motus file:

1. allambigs: lists in long-data format each motusTagID (up to 6) associated with each negative ambigID.
2. alltags: provides the full detection data for all tags, and all ambiguous (duplicate) tags  associated with your project. Ambiguous detections are repeated for each motusTagID represented by each ambigID. 

Because the file is a dplyr::src_sqlite file, all of the dplyr functions can be used to filter and summarize the .motus database, without needing to first save the data as a *flat* file (a typical two-dimensional dataframe). The SQL format is very advantageous when you have a large file -- the queries using SQL will be substantially faster than those done on a dataframe. 

Each table in the .motus file can be accessed using the tbl() function. 

```{r getTable, eval = FALSE}

## get the tag deployment metadata view for the current project
tbl.tagDeps <- tbl(sql.motus, "tagDeps")
     
```

The underlying structure of these tables is a list of length 2:

```{r dfStructure, eval = FALSE}

str(tbl.tagDeps)

```

The first part of the list, 'src', is a list that provides details of the SQLiteConnection, including where the database is stored. The second part is a list that includes the underlying table. Thus, the R object 'tagMeta' is a *virtual* table that stores the database structure and information required to connect to the underlying data in the .motus file. As stated above, the advantage of storing the data in this way is that it saves memory when accessing very large databases, and the dplyr package can be used to manipulate and summarize the tables before collecting the results into a typical "flat" format dataframe.

If you want to use familiar functions to get access to components of the underlying data frame, then use the 'collect' function. For example, to look at the names of the variables in tagMeta:

```{r}

tbl.tagDeps %>% 
  collect() %>%
  names() # list the variable names in the table

```

The *virtual* table 'alltags' contains the detection data, along with all metadata variables that most users will ever need from the various underlying .motus tables. It too is accessed using the dplyr tbl() function:  

```{r getAllTagsTable, eval = FALSE}

tbl.alltags <- tbl(sql.motus, "alltags") ## virtual table

```

The following table lists the variables available in the 'alltags' view, a full description of each field is available in \@ref(appendixB)

```{r parameterTable, echo = FALSE}

tbl.alltags %>% 
      collect() %>%
      names()

```

## Convert a SQLITE table to a flat dataframe {#convertToFlat}

To convert the 'alltags' view or other table in the .motus file into a typical 'flat' format, i.e., with every record for each field filled in, use the collect() and as.data.frame() functions.  The output can then be further manipulated, or used to generate a RDS file of your data. 

We suggest that a good workflow is to prepare a script that downloads/updates your data, filters out the necessary variables, and saves the resulting data as an RDS file. We suggest using RDS instead of CSV, because the RDS format preserves the underlying structure of the data (e.g. POSIX times stay as POSIX times). If you want to export your data to another program, then a CSV format might be preferred.

We caution that producing a flat file using the full suite of fields can chew up a lot of memory, and can slow R down considerably when dealing with large datasets. This is the point in your workflow where you should remove any unwanted variables. You can always change your mind and return to this script, creating a new RDS file with additional or different variables.

```{r collect, eval = FALSE}

df.alltags <- tbl.alltags %>% 
                collect() %>% 
                as.data.frame()      ## for all fields in the df (data frame)

```

And take a quick look at the resulting file. 

```{r quickLook, eval = FALSE}

names(df.alltags)     ## field names
str(df.alltags)       ## Look at the structure of your data fields
head(df.alltags)      ## Look at first 6 rows of your df
summary(df.alltags)   ## summary of each column in your df

```

Note that the format of the time stamp (ts) field is numeric and represents seconds since January 1 1970. We recommend that when you transform your tables into flat dataframes, that you format the time stamp using the lubridate package at that time, e.g.:

```{r collect_TimeStamp, eval = FALSE}

df.alltags <- tbl.alltags %>% 
                collect() %>% 
                as.data.frame() %>%     ## for all fields in the df (data frame)
                mutate(ts = as_datetime(ts, tz = "UTC", origin = "1970-01-01"))

## the tz = "UTC" is not necessary here, provided you have set your system time to UTC/GMT 
```

If you want to load only part of your entire virtual table (e.g. certain fields, certain tags, or all tags from a specified project or species), you can use dplyr funtions to filter the data before collecting into a dataframe.  Some examples are below:

1. To select certain fields:

```{r collect1, eval = FALSE}

## to grab a subset of fields, in this case a unique list of motus tag IDs 
## at each receiver and antenna.
df.alltagsSub <- select(tbl.alltags, recv, ant, motusTagID) %>%
  distinct() %>% 
  collect() %>% 
  as.data.frame() 

```

2. To select certain tag IDs:

```{r collect2, eval = FALSE}
## filter to include only motusTagIDs 9939, 25643
df.alltagsSub <- filter(tbl.alltags, motusTagID %in% c(16011, 23316)) %>% 
                  collect() %>% 
                  as.data.frame() %>%    
                  mutate(ts = as_datetime(ts, tz = "UTC", origin = "1970-01-01"))    

```

3. To select a specified species:

```{r collect3, eval = FALSE}

## filter to only Red Knot (using speciesID)
df.4670 <- filter(tbl.alltags, speciesID == 4670) %>%  
  collect() %>% 
  as.data.frame() %>%    
  mutate(ts = as_datetime(ts, tz = "UTC", origin = "1970-01-01"))  

## filter to only Red Knot (using English name)
df.redKnot <- filter(tbl.alltags, spEN == "Red Knot") %>%   
  collect() %>% 
  as.data.frame() %>%    
  mutate(ts = as_datetime(ts, tz = "UTC", origin = "1970-01-01"))    

```

Using dplyr(), your virtual table can also be summarized before converting to a flat file. For example, to find the number of different detections for each tag at each receiver:

```{r collectSum, eval = FALSE}

df.detectSum <- tbl.alltags %>% 
  group_by(motusTagID, recv) %>%
  tally() %>%
  collect() %>%
  as.data.frame() 

```

In later chapter(s) we will show you additional ways of summarizing and working with your data.

## Export your 'flat' dataframe to CSV or RDS file {#exportDetections}

A good workflow is to create a script that deals with all of your data issues, then saves a dataframe (or workspace) for re-use. If you do this, you can quickly start an analysis or visualization session from a known (and consistent) starting point. When working in R, we do this is by using an RDS file, which preserves all of the associated R data structures (such as time stamps).

```{r createRDS, eval = FALSE, message = FALSE, warning = FALSE}

## save an RDS file

saveRDS(df.alltags, "./data/df.alltags.RDS")  

## or save as CSV file, which does not preserve time stamps, but is more universally accepted

write_csv(df.alltags, "./data/df.alltags.CSV")

```

## R object naming convention

Throughout this chapter and the rest of the book, we name R objects according to their structure and the source of the data contained in the object. So, SQLite objects will be prefixed with "sql.", virtual table objects will be prefixed with "tbl.", and dataframe objects will be prefixed with "df."; the rest of the name will include the name of the .motus table that the data originates from. For example, for the alltags table in the sample.motus file:

```{r namingConvention, eval = FALSE}

sql.motus <- tagme(176)                   # SQLite R object, which links to the .motus file
tbl.alltags <- tbl(sql.motus, "alltags")  # virtual table object of the alltags table in the
                                          # sample.motus file
df.alltags <- tbl.alltags %>%
                collect() %>%
                as.data.frame() %>%        # dataframe ("flat") object of the alltags table
                mutate(ts = as_datetime(ts, tz = "UTC", origin = "1970-01-01"))              

```