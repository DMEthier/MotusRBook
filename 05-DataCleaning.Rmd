# Data Cleaning {#dataCleaning}

There are three sources of 'error' that can result in tag detections appearing in your database that are incorrect.  
First, random radio noise ('static') can be detected and interpreted to be the transmission of a tag. These are called 'false positives'.   

Second, despite our best efforts to avoid it, duplicate tags are sometimes transmitting in the network at the same time. When two tags are deployed at the same time that have the same Lotek ID code, burst interval, and nominal transmit frequency, it results in situations where the detections may belong to either tag, but there is no information (other than contextual information) to separate them. We term these 'Ambiguous tags'. 

Third, a tag can appear to be present when two tags are transmitting at the same time that by chance produce a signal that looks like a third tag that is not in fact present. Such tags are most common at roosting sites or breeding colonies, where many tags are transmitting simultaneously. We term these 'Aliased tags'.   

Here we provide example workflows to deal with each of these possible problems. We start by working with false positives, before exploring the other types of error.

## False Positives {#falsePositives} 

1) Run length (runLen): A run is a group of consecutive detections of a tag detected on a single antenna at a single receiver. In general, a detection with a run length of 2 has a high probability of being a false positive detection. With the exception of a few 'quiet' stations with little noise, we generally recommend that you filter out all detections with a run length of 2. However, because you will likely lose some true detections in the process, we also recommend that after a full analysis of your data, you return to these detections and examine them individually, to determine (usually contextually) if they can be considered real.

2) Standard deviation of frequency offset (freqsd): Standard deviation of frequency offset among pulses in a burst may provide some information about false positive detections. These data are collected by SensorGnome receivers only. We do not have specific recommendations here regarding the use of this statistic at the present time, but are exploring its potential use. If you choose to use freqsd to filter data, we suggest that you carefully examine the detections you are removing.

The *goal of this chapter* is to provide you with the tools you need to check your data for false detections, and create a filter to remove them from your data. 

We do so using the following steps: 

1) Run a preliminary filter to remove all detections with runLen = 2. 

2) Determine how many of your tags may be ambiguous detections. 

3) Provide a workflow for examining individual tags, and determining if runs in those tags are errors. 

4) Create a custom data filter that is associated with your Motus login credentials.

## Load required packages

Follow the instructions in Chapter \@ref(loadingPackages) to install the following packages before loading, if they are not already installed.

```{r loadpackages.5, message = FALSE, warning = FALSE}

Sys.setenv(tz="GMT")

library(devtools)
library(motus)
library(tidyverse)
library(lubridate)
library(rworldmap) # for mapping

```

## Load detections data

Recall from \@ref(accessingData) that when accessing the sample database, you will need to input "motus.sample" in the R console as both username and password when prompted by the tagme() user authentication process. This section assumes you have already completed the initial sample data download. 

When accessing the alltags table, we remove some unecessary variables. We also create receiver latitude and longitude variables that are based on the coordinates recorded by the receiver GPS, and where those are not available, infilled with coordinates from the receiver deployment metadata. We use the collect() and as.data.frame() statements to transform the dataframe into a 'flat' file, and then transform all time stamp variables from seconds since January 1 1970 to datetime (POSIXct) format.

```{r importData5}

proj.num <- 176

## load detection data, select variables, create latitude variables, and transform to flat file
## in here, we also fix up some sites that are missing receiver deployment data, or do not have names
## As more users explore (and fix!) their metadata, these missing values should begin to disappear.
sql.motus <- tagme(proj.num, update = FALSE, dir = "./data/")
tbl.alltags <- tbl(sql.motus, "alltags")


## FIXME! this should be a user-created function, since it gets used multiple times.

df.alltags <- tbl.alltags %>% 
                mutate(recvLat = if_else((is.na(gpsLat)|gpsLat == 0), recvDeployLat, gpsLat),
                       recvLon = if_else((is.na(gpsLon)|gpsLon == 0), recvDeployLon, gpsLon),
                       recvAlt = if_else(is.na(gpsAlt), recvDeployAlt, gpsAlt)) %>%
                select(-noise, -slop, -burstSlop, -done, -bootnum, -mfgID, -codeSet, -mfg, -nomFreq,
                       -markerNumber, -markerType, -tagDeployComments, -fullID, -deviceID,
                       -recvDeployLat, -recvDeployLon, -recvDeployAlt, -speciesGroup, -gpsLat, 
                       -gpsLon, - recvAlt, - recvSiteName) %>%
                collect() %>%
                as.data.frame() %>%
                mutate(ts = as_datetime(ts),  # work with dates AFTER transforming to flat file
                       tagDeployStart = as_datetime(tagDeployStart),
                       tagDeployEnd = as_datetime(tagDeployEnd), 
                       recvLat = plyr::round_any(recvLat, 0.05), 
                       recvLon = plyr::round_any(recvLon, 0.05),
                       recvDeployName = if_else(is.na(recvDeployName), 
                                                paste(recvLat, recvLon, sep=":"), recvDeployName))

## or just select the variables you need
#select(runID, ts, sig, freqsd, motusTagID, ambigID, runLen, tagProjID, 
#       tagDeployStart, tagDeployEnd, etc.)

```

## Preliminary data checks

Prior to filtering the data, we do a few summaries and plots of the data.

**1.  Summarize the detections of your tags**

First, determine which project tags have detections, and determine how many are of run length = 2. Apart from the tag not being within range of a receiver station, there are several reasons why deployed tags might not be detected, including:

1) The tag was not properly activated on deployment. To avoid this, always check that a tag is active using a hand-held receiver before attaching the tag to your study animal and releasing it. 

2) An animal with a properly activated tag might not have passed within range of a receiving station. Study designs that incorporate strategic placement of receivers to meet project goals can improve your odds of getting detections of your tags.  

3) Missing or incorrect tag deployment metadata in the Motus database can result in the tagFinder not 'looking' for your tag at the time the tag was deployed, or at all. Please ensure your tag metadata are entered correctly.  

Using the following code, we see there are detections for 18 tags deployed by the sample project, and that many have run lengths of 2:

```{r ntagsDetections}

df.alltags %>%
  filter(tagProjID == proj.num) %>% # subset to include only tags registered to project
  mutate(rl.gt.2 = runLen == 2) %>%
  group_by(motusTagID, rl.gt.2) %>%
  tally() %>%
  spread(key = rl.gt.2, value=n)

```

Although some of these may be valid detections, we have found it simpler to just remove them from our analysis, and possibly revisit them at a later stage. So we now filter on runLen (> 2) for our subsequent operations.

```{r filterRunLen2}

df.alltags.sub <- filter(df.alltags, 
                         runLen > 2)

```

An initial view of the data is best achieved by plotting. We will show you later how to plot detections on a map, but we prefer a simpler approach first; Plotting detections through time by both latitude and longitude. First however, we should simplify the data. We'll actually create a little function here, since we'll use this code over again. 

**3. Simplify the data for plotting**

```{r fun.getpath}

## simplify the data by summarizing by the runID. 
## if you want to summarize at a finer (or coarser) scale, you can also create 
## a rounded timestamp variable using 
## mutate(ts.h = plyr::round_any(ts, 3600) function call. 
## Other options are to just use date (e.g date = as_date(ts))

## initially filter by tagProj and runLen,  to get rid of most false positives
## FIXME! ... remove the filter by recvLat when that is fixed in the sample database

## 
fun.getpath <- function(df) 
  {
  df %>%
    filter(tagProjID == proj.num, # keep only tags registered to the sample project
                           !is.na(recvLat) | !(recvLat == 0)) %>% 
    group_by(motusTagID, runID, recvDeployName, ambigID, 
             tagDeployLon, tagDeployLat, recvLat, recvLon) %>%
    summarize(max.runLen = max(runLen), ts.h = mean(ts)) %>%
    arrange(motusTagID, ts.h)
  } ## end of function call

df.alltags.path <- fun.getpath(df.alltags.sub)
                    
```

We would initially plot a subset of tags by either latitude or longitude, to get an overview of where there might be issues. Here, to simplify the example, we plot only six tags. We avoid the ambiguous tags for now. 

```{r plot1.5 fig.width=12, fig.height=5}

p <- ggplot(data = filter(df.alltags.path, 
                          motusTagID %in% c(16011, 16035, 16036, 16037, 16038, 16039)), 
            aes(ts.h, recvLat)) 
p + geom_point() + 
  geom_path() + 
  facet_wrap(~motusTagID, scales = "free", ncol=2) + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

```
It is immediately apparent that there may be an issue with some tags showing up around 44 degrees during in the winter, which is possible but unlikely. Let's examine these tags in more detail by going back to the original data frame, and examining the runs.

```{r examineRuns}

filter(df.alltags.sub, month(ts) %in% c(12, 1),
       motusTagID %in% c(16036, 16038, 16039)) %>% 
  group_by(recvDeployName, month(ts), runLen) %>%
  summarize(n = length(ts), 
            n.tags = length(unique(motusTagID)))

```

These detections were at sites around the Canadian Maritimes (Sable Island, Grand Manan) and were run lengths of 3. These are all indicators of likely false postives. We'll now start a tally of the particular runs involved, so that we can collate them in to a filter later. 

If you are interested, you can re-run the code above, but on the full data frame (df.alltags) containing run lengths of 2. You will see that there are additional false positive detections at these sites, that are already eliminated by filtering on runLen > 2. These additional detections provide further evidence that these sites experienced some radio noise during these particular months, resulting in some false positive detections.

You may also be interested more generally in exploring which data have only short run lengths. For example, the following code shows the maximum run length at all sites by month (for those runs with runLen > 2).

```{r noisySites}

df.alltags.sub %>%
  mutate(month = month(ts)) %>%
  group_by(recvDeployName, month) %>%
  summarize(max.rl = max(runLen)) %>%
  spread(key=month, value=max.rl)

```

Or, get a list of sites where the maximum run length of detections was never greater than (say) 4, which may sometimes (but not always!) indicate they are simply false detections.

```{r}

df.alltags.sub %>%
  mutate(month = month(ts)) %>%
  group_by(recvDeployName, month) %>%
  summarize(max.rl = max(runLen)) %>%
  filter(max.rl < 5) %>%
  spread(key=month, value=max.rl)

```

It is impossible here to go through every possible issue; users are encouraged to explore their data fully, and make reasoned decisions on which detections are unlikely or indeterminate. We will show you how to collect all of these into a filter, which can then be routinely applied to your data prior to analysis. 

For now, we'll save a vector of the runIDs for the offending false positives (we'll use this vector later to create a permanent filter) and then re-run the plot with these values removed.

```{r createRunsFilter}

## create the filter

runID.block.1 <- filter(df.alltags.sub, month(ts) %in% c(12, 1),
       motusTagID %in% c(16036, 16038, 16039)) %>%
  pull(runID) %>%
  unique()

## use the function we created earlier to make a new 'path' data frame for plotting
df.alltags.path <- fun.getpath(filter(df.alltags.sub, 
                                      motusTagID %in% c(16011, 16035, 16036, 16037, 16038, 16039), 
                                      !(runID %in% runID.block.1)))

p <- ggplot(data = df.alltags.path, aes(ts.h, recvLat)) 
p + geom_point() + 
  geom_path() + 
  facet_wrap(~motusTagID, scales = "free", ncol=2) + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

```

We can see that most of these now make more sense, with tags 16035, 16037 and 16039 having been detected during migration, in what appears to be a reasonable latitudinal progression with time, and the other three tags which were not detected very far away from their deployment location. 

The reader is encouraged to explore the rest of the tags within this group, to determine if there are additional false positives. 

## Examining ambiguous detections (#ambigs)

Before we go further, we should check to see if any tags have ambiguous detections -- we may want to use this information to help with further filtering. 

**2. Are any of your tags associated with ambiguous detections?**

The clarify() function in the motusClient R package provides a summary of ambiguities in the detections data. Each ambigID refers to a selection of detections that could belong to one or more (up to 6) motusTagIDs, which are listed in the id1 to id6 fields:

```{r checkForAmbigs}

clarify(sql.motus)

```

We can see that there are six tags with ambiguous detections within this data set. Detections associated with five of the six ambigIDs could belong to one of two tags, and detections associated with one ambigID (-171) could belong to one of three tags. The fullID fields list the project names associated with the duplicate tags (e.g., "SampleData", "Selva", "Niles"), along with features of the tags (manufacturer tag ID, burst, and transmit frequency).

Let's get a vector of these, and do some plots to see where there may be issues. 

```{r examineAmbigs}

df.ambigTags <- select(df.alltags.sub, ambigID, motusTagID) %>%
  filter(!is.na(ambigID)) %>%
  distinct() 

```

Using our getpath function, we'll create paths and another plot of these detections. We'll add some information to the plot, showing where (in time) the tags are actually ambiguous. FIXME! (Explain this better).

```{r plotAmbigs}

df.alltags.path <- fun.getpath(filter(df.alltags.sub, 
                                      motusTagID %in% df.ambigTags$motusTagID, 
                                      tagProjID == proj.num)) %>%
  mutate(Ambiguous = !(is.na(ambigID))) ## create a boolean variable for ambiguous detections

## to put all ambiguous tags from the same project on the same plot together, we need to create
## a new 'ambig tag' variable we call 'newID. 

ambigTags.2 <- filter(df.alltags.sub) %>%
  select(ambigID, motusTagID) %>%
  filter(!is.na(ambigID)) %>%
  distinct() %>%
  group_by(ambigID) %>%
  summarize(newID = paste(unique(ambigID), toString(motusTagID), sep = ": ")) %>%
  left_join(df.ambigTags, by="ambigID")

## and merge that with df.alltags.path
df.alltags.path <- left_join(df.alltags.path, ambigTags.2, by="motusTagID") %>%
  arrange(ts.h)

p <- ggplot(data = df.alltags.path, aes(ts.h, recvLat, group = Ambiguous, colour=Ambiguous)) 
p + geom_point() + 
  geom_path() + 
  facet_wrap(~newID, scales = "free", ncol=2) + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

```

Let's deal with the easy ones first. 

**ambiguous tag -337**
**motusTagID 10811 and 16011:**

Ambiguous tag -337 is ambiguous only at the beginning of the deployment, but was detected at the exact latitude of deployment, and just before the non-ambiguous detections. So the issue is simply that the tail end of the previous deployment (by another project) overlaps with our deployment. We can claim these tags as our own, and remove the other ambiguous detections.

**ambiguous tag -134**
**motusTagID 22905 and 23319:**

Similarly, there are ambiguous detections of tag -134 at the same latitude and the same time frame as the unambiguous deployment of that tag. We can reasonably consider these to belong to our tag. However, the non-ambiguous part of tag -134 that occur in mid-April -- are early for a Red Knot to be flying through southern Ontario so let's inspect them. 

```{r checkAmbigs}

filter(df.alltags.sub, motusTagID == 22905, month(ts) == 4) %>%
  select(runID, batchID, ts, freqsd, runLen)

```

We see two separate runs of length 3 each, separated by 3 days. If we inspect the rest of this batch (that is, if we also look at run lengths of 2) ... 

```{r}

filter(df.alltags, batchID == 79646) %>% select(runLen, recvDeployName) %>%
  group_by(runLen, recvDeployName) %>%
  tally()

```

... we can see that there are many false positives at this tower around the same time (within the same batch) and so the run lengths of 3 are likely false positives.


**ambiguous tag -171**
**motusTagID 22778, 22902 and 22403:**

The ambiguous detections for this tag, which occur in the Great Lakes region, could also belong to motusTagID 22778 from the RBrownAMWO project or motusTagID 24303 from the Neonics project. Let's take a closer look at these detections.

First, find the deployment dates and locations for each tag. 

```{r}

filter(df.alltags, ambigID == -171) %>% 
  filter(!is.na(tagDeployStart)) %>%
  select(motusTagID, tagProjID, start=tagDeployStart, end=tagDeployEnd, 
         lat=tagDeployLat, lon=tagDeployLon, species=speciesEN) %>%
  distinct() %>%
  arrange(start)

```

And plot the detections. 

```{r}

df.ambig.171 <- filter(df.alltags.sub, ambigID == -171)

p <- ggplot(data=df.ambig.171, aes(ts, sig, colour=as.factor(port)))
p + geom_point() + geom_smooth(method="loess", se=FALSE) + 
  facet_wrap(as_date(ts) ~ recvDeployName, scales = "free_x") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))


```

We see that there are a large number of detections of this tag on 10 May 2017 at Old Cut (Long Point, Lake Erie, Canada), consistent with a bird 'hanging around'. Subsequent detections on the 18th of May are also at Old Cut, and then a location to the North of Old Cut (unregistered receivers) that are consistent with a bird departing on migration. Note the pattern in these latter two panels of increasing then decreasing signal strength which indicates a bird is flying through the beam of an antenna.


**ambiguous tag -114**
**motusTagID 22897 and 24298:**

Next we look at the similar ambiguities for ambiguous tag -114.

```{r ambig141}

filter(df.alltags, ambigID == -114) %>% 
  filter(!is.na(tagDeployStart)) %>%
  select(motusTagID, tagProjID, start=tagDeployStart, end=tagDeployEnd, 
         lat=tagDeployLat, lon=tagDeployLon, species=speciesEN) %>%
  distinct() %>%
  arrange(start)

```

We again subset these and plot them. An initial plot suggested that all of the detections are of a migratory flight, so we construct a somewhat different plot, to emphasize this. 

```{r ambig141b}

df.ambig.114 <- filter(df.alltags.sub, ambigID == -114)

p <- ggplot(data=df.ambig.114, aes(ts, sig, colour=as.factor(port)))
p + geom_point() +  
  facet_wrap(as_date(ts) ~ paste(recvLat, recvDeployName, sep=": "), scales = "free_x") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

p <- ggplot(data=df.ambig.114, aes(ts, sig, colour=paste(recvLat, recvLon, recvDeployName, sep=": ")))
p + geom_point() + scale_colour_discrete(name="Lat/Lon and\nStation Name") + 
  facet_wrap(~as_date(ts), scales = "free_x")
```

Notice that the detections are consistent with a migratory departure from the Long Point area (Old Cut Field Station, Lake Erie, Ontario). 

**ambig -106**
**motusTagID 17021 and 17357:**

The complete run overlaps. 

```{r ambig106}

filter(df.alltags, ambigID == -106) %>% 
  filter(!is.na(tagDeployStart)) %>%
  select(motusTagID, tagProjID, start=tagDeployStart, end=tagDeployEnd, 
         lat=tagDeployLat, lon=tagDeployLon, species=speciesEN) %>%
  distinct() %>%
  arrange(start)

```
```{r ambig106b}

df.ambig.106 <- filter(df.alltags.sub, ambigID == -106)

p <- ggplot(data=df.ambig.106, aes(ts, sig, colour=paste(recvLat, recvLon, recvDeployName, sep=": ")))
p + geom_point() + scale_colour_discrete(name="Lat/Lon and\nStation Name") + 
  facet_wrap(~as_date(ts), scales = "free_x")

```

Both sets of detections are long run lengths, and look valid (increasing then decreasing signal strength). These detections are >1000 km distant from one another, and so must represent two individuals. The gray-cheeked thrush tag is near the end of its presumed life. One would have to make an informed biological decision as to which individual was most likely at either particular location at that time, in order to determine which tag belonged to which individual. 

Keep in mind that it remains possible that someone deployed yet 

We can look at which species were detected in the batchs around each of the detections, which might give some clarity. 

```{r ambig106c}

filter(df.alltags, batchID %in% unique(df.ambig.106$batchID)) %>%
  group_by(speciesEN, batchID) %>%
  summarize(n.tags = length(unique(motusTagID))) %>%
  spread(key=batchID, value=n.tags)

```

```{r}
filter(df.alltags, batchID %in% unique(df.ambig.106$batchID)) %>%
  select(recvDeployName, batchID) %>%
  distinct()
```


So we see that there were other Semipalmated and White-rumped sandpipers with the batch on the shore of Hudson Bay (recvDeployName: 51.3:-80.1) but not with the other batches. It seems therefore that the MDR detection is most likely that of the Gray-cheeked Thrush.

**ambig -56**
**motusTagID 22905 and 23319:**

```{r ambig56}

filter(df.alltags, ambigID == -56) %>% 
  filter(!is.na(tagDeployStart)) %>%
  select(motusTagID, tagProjID, start=tagDeployStart, end=tagDeployEnd, 
         lat=tagDeployLat, lon=tagDeployLon, species=speciesEN) %>%
  distinct() %>%
  arrange(start)

```

Tag 23316 was deployed by the James Bay Shorebird Project (Sample Project) about three weeks after tag 22867, from a slightly different location. 

```{r ambig56b}

df.ambig.56 <- filter(df.alltags.sub, ambigID == -56) %>%
  mutate(sig = ifelse(sig > 0, sig * -1, sig))

p <- ggplot(data=df.ambig.56, 
            aes(ts, recvLat, colour=paste(recvLat, recvLon, recvDeployName, sep=": ")))
p + geom_point() + scale_colour_discrete(name="Lat/Lon and\nStation Name") 

```
It seems that anything informative occurs between about 9-11 October, so let's zoom in on that part of the data set. 

```{r ambig56c}

ts.begin <- ymd_hms("2016-10-06 00:00:00")
ts.end <- ymd_hms("2016-10-12 23:00:00")
p <- ggplot(data=filter(df.ambig.56, 
                        ts > ts.begin, 
                        ts < ts.end),
            aes(ts, recvLat, colour=paste(recvLat, recvLon, recvDeployName, sep=": ")))
p + geom_point() + scale_colour_discrete(name="Lat/Lon and\nStation Name") 

```
We can see that the tag was detected consistently at Niapiskau before and after the period when it was also detected to the north (at Washkaugou and Piskwamish) and to the south by filtering out the portion of the data not near Niapiskau, and using the siteTrans function from the motus package. 

```{r ambig56d}

df.56.tmp <- filter(df.ambig.56, !(recvLat == 50.2), motusTagID == 22867) ## the other is a duplicate

siteTrans(df.56.tmp, latCoord = "recvLat", lonCoord = "recvLon") %>%
  ungroup() %>%
  filter(rate < 60) %>% ## get rid of simultaneous detections
  mutate(total.time = round(seconds_to_period(tot_ts))) %>%
  select(start=recvDeployName.x, end=recvDeployName.y, date=ts.x, "rate(m/s)" = rate, 
         dist, total.time = total.time, bearing)

```

The bird made a 14.5 hour flight at a rate of 24 m/s, which is plausible. The researchers involved may have other data to support the inference (e.g. an actual sighting of the Red Knot still in Niapiskau after this flight was recorded) but it seems likely that the ambiguous detections can be reasonably divided between the two individuals. 

** filtering **
In here, need to re-do all of the filtering, in a single place. 

Now, we need to combine our inference from above into a single place, and create a filter for future user. 

runlen > 2. 
each tag. 


```{r writeFilter2}

writeRunsFilter(sql.motus, "filtAmbigFalsePos", motusProjID = 176, df = df.tagRuns, delete = TRUE)

```

To append new records to the filter, leaving previous records intact, use the overwrite = FALSE statement (not evaluated here):

```{r overwriteFilter3, eval = FALSE}

writeRunsFilter(sql.motus, "filtAmbigFalsePos", df = df.tagRuns, overwrite = FALSE)

```

Apply the filter to the .motus file, and re-format the data into a flat file before continuing to the next step. Note that this code is *exactly* the same as in the previous section; the only difference is that the 'filtAmbigFalsePos' filter now contains more runIDs to filter out of the data:

```{r overwriteFilter4}

# load the .motus file
sql.motus <- tagme(176, update = FALSE, dir = "./data/")

# apply the filter; a dataframe is output
df.alltags.sub <- applyRunsFilter(sql.motus, "filtAmbigFalsePos", p.min = 0.1)

# manage the dataframe
df.alltags.sub <- df.alltags.filt %>%
                      filter(motusTagID %in% tag.subset) %>%
                      mutate(recvLat = if_else((is.na(gpsLat)|gpsLat == 0), recvDeployLat, gpsLat),
                             recvLon = if_else((is.na(gpsLon)|gpsLon == 0), recvDeployLon, gpsLon),
                             recvAlt = if_else(is.na(gpsAlt), recvDeployAlt, gpsAlt),
                             ts = as_datetime(ts),  # work with dates AFTER transforming to flat file
                             tagDeployStart = as_datetime(tagDeployStart),
                             tagDeployEnd = as_datetime(tagDeployEnd)) %>%
                      select(-noise, -slop, -burstSlop, -done, -bootnum, -mfgID, -codeSet, -mfg,
                             -nomFreq, -markerNumber, -markerType, -tagDeployComments, -fullID,
                             -deviceID, -recvDeployLat, -recvDeployLon, -recvDeployAlt, 
                             -speciesGroup, -gpsLat, -gpsLon, - recvAlt, - recvSiteName) %>%
                      collect() %>%
                      as.data.frame()

```

## Filter the data

The Motus R package offers functionalities to create custom filters for your data (see \@ref(#appendixC)). The filters, once created, are attached to your user profile (motus login credentials), and can be used to 1) assign probabilities to detections, and 2) filter detections based on those probabilities each time you load your .motus file. A filter is created, populated, and applied in the following steps:

1. use the 'createRunsFilter' function to create (but not populate) a filter, here named 'filtAmbigFalsePos'. 

2. Generate a dataframe which includes the motusTagID and runID of detections you want to filter; assign a probability to those detections. In this case, because we want to exclude the data we are filtering, we assign a probability of 0 to all detections we consider to be false positives.  

3. Use the 'writeRunsFilter' function to write the dataframe to the filter. Using the delete = TRUE option will remove all records previously written to the filter; using the overwrite = FALSE option will allow new records to be appended to the filter.  

4. Use the 'applyRunsFilter' function to output a flat file of the alltags dataframe with probabilities assigned to each detection. Detections that are not included in the filter will be automatically assigned a probability of 1. Note that to also filter the data by a given probability, you must use the 'p.min =' statement. In this case, we use p.min = 0.1, which drops all detections with a probability less than that value.  

### Create a custom data filter for your .motus file

```{r createFilter, eval = FALSE}

createRunsFilter(sql.motus, 
                 filterName = "filtAmbigFalsePos", 
                 motusProjID = 176, 
                 descr = "filter to assign probability = 0 to false positive detections and ambiguities that belong to other tags (Chapter 5 in R Book)")

```

Check that the filter was created using the 'listRunsFilters' function; note that the filter has been assigned a unique filterID of 1:

```{r listRunsFilters.5}

listRunsFilters(sql.motus)

```

### Filter detections with run length = 2 and standard deviation of frequency offset >= 0.1


To filter all detections with a runLen = 2 and/or a standard deviation of frequency offset >= 0.1 (remember that frequency offset only applies to SensorGnome receivers), generate a dataframe, here named 'df.tagRuns', that includes the motusTagID and runID of detections with a runLen = 2 and freqsd >= 0.1. A probability of 0 is assigned to those records:

```{r filterRunLen}

df.tagRuns <- df.alltags.sub %>%
#  filter(freqsd >= 0.1|runLen == 2) %>%
  filter(runLen == 2) %>%
  select(motusTagID, runID) %>%
  mutate(probability = 0) %>%
  distinct()

```

Then, populate the 'filtAmbigFalsePos' filter using the `writeRunsFilter` function. To remove previously written detections from the filter, use the delete = TRUE option:

```{r writeFilter1}

writeRunsFilter(sql.motus, "filtAmbigFalsePos", motusProjID = 176, df = df.tagRuns, delete = TRUE)

```
Check that the records were applied to the filter using the 'getRunsFilters' function:

```{r getRunsFilter1}

df.check <- getRunsFilters(sql.motus, "filtAmbigFalsePos")
head(df.check)

```

Finally, apply the filter to the .motus file. We filter the data by those probabilities by assigning a p.min = 0.1, which drops all detections associated with a probability < 0.1.

Note also that because the filter is applied to the .motus file and not our flat file, we need to re-create the flat file. Going forward, once the filter is completely populated, you will only need to do this when you first import your .motus file. Here, we start from tagme() to show you how the filter would be applied when you first import your data:

```{r overwriteFilter1, eval = FALSE}

# load the .motus file
sql.motus <- tagme(176, update = FALSE, dir = "./data/")

```

```{r overwriteFilter2}

# manage the dataframe
df.alltags.filt <- df.alltags.filt %>%
                      filter(motusTagID %in% tag.subset) %>%
                      mutate(recvLat = if_else((is.na(gpsLat)|gpsLat == 0), recvDeployLat, gpsLat),
                             recvLon = if_else((is.na(gpsLon)|gpsLon == 0), recvDeployLon, gpsLon),
                             recvAlt = if_else(is.na(gpsAlt), recvDeployAlt, gpsAlt),
                             ts = as_datetime(ts),  # work with dates AFTER transforming to flat file
                             tagDeployStart = as_datetime(tagDeployStart),
                             tagDeployEnd = as_datetime(tagDeployEnd)) %>%
                      select(-noise, -slop, -burstSlop, -done, -bootnum, -mfgID, -codeSet, -mfg, -nomFreq, -markerNumber, -markerType, -tagDeployComments, -fullID, -deviceID, -recvDeployLat, -recvDeployLon, -recvDeployAlt, -speciesGroup, -gpsLat, -gpsLon, - recvAlt, - recvSiteName) %>%
                      collect() %>%
                      as.data.frame() %>%
                      mutate() 

```


