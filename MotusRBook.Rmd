---
title: "Motus R Book"
author: "Tara L. Crewe, Zoe Crysler, and Philip Taylor"
date: "`r Sys.Date()`"
output: bookdown::gitbook
documentclass: book
site: bookdown::bookdown_site
cover-image: BSC_Motus_Logo.png

---

# A walk through the use of R for Motus automated radio-telemetry data  {-}

```{r coverimage, echo=FALSE, out.width="700px", fig.align='center'}
knitr::include_graphics("images/MotusBSCLogo.png")
```

Our goal with this online 'handbook' is to show Motus (<https://motus.org>) users how to use the R statistical programming language (<https://www.r-project.org/>) to import tag detections data for a project or receiver; clean data and filter false positives; explore detections data through visualizations and summaries; transform the data, e.g., by determining time since sunrise/sunset or magnetic declination; and run various analytical procedures. We hope the contents will be of use, and if you have suggestions for additional examples, please let us know by emailing motus@birdscanada.org. 

Version 1.0 
Published January 2018




<!--chapter:end:index.Rmd-->

# Introduction {#introduction}

```{r fig1, echo=FALSE}
knitr::include_graphics("images/Motus-System-IG-final.png")
```

 <br>

The Motus Wildlife Tracking System ('Motus'; Taylor et al. 2017; <https://www.motus.org>) is an international, collaborative automated radio-telemetry network to track the movement and behaviour of flying organisms affixed with digitally encoded radio-transmitters. Motus was developed at Acadia University in 2012-2013. In 2014, a major infrastructure expansion was made possible through a Canada Foundation for Innovation grant to Western University, The University of Guelph, and Acadia University. Since then, Motus has grown through the collaboration of independent researchers and organizations <https://motus.org/about/>. It is now managed as a program of Bird Studies Canada (<https://www.birdscanada.org>) in partnership with Acadia University. 

Motus is unique among automated telemetry arrays in that all researchers in a geographic region (e.g., the Americas or Europe) use a shared radio frequency. This allows tagged animals to be detected by any receiving station across the network, greatly broadening the spatial scope of potential research questions. Motus users also use a shared data infrastructure and web portal: all data collected from across the network are centrally stored and archived, which allows users to access detections of their tags by anyone's receiver in the network, and individuals that maintain receivers have access to all detections of anyone's tags on those receivers.

Having a shared data infrastructure also means that users can benefit from R functions written specifically for Motus data by any and all users. The Motus R package described in this book is in continual development, and the intent of this online 'handbook' is to help users learn the various functionalities of the package, and potentially contribute to it. We also show how additional R packages such as ggplot can be used to explore, visualize, transform, and analyze Motus data. 

The content of the handbook will continue to evolve and grow along with the analytical needs of the network. Those interested in contributing code to the Motus R package or this handbook can send proposed additions to motus@birdscanada.org.  

Taylor, P. D., T. L. Crewe, S. A. Mackenzie, D. Lepage, Y. Aubry, Z. Crysler, G. Finney, C. M. Francis, C. G. Guglielmo, D. J. Hamilton, R. L. Holberton, P. H. Loring, G. W. Mitchell, D. R. Noriis, J. Paquet, R. A. Ronconi, J. Smetzer, P. A. Smith, L. J. Welch, and B. K. Woodworth. 2017. The Motus Wildlife Tracking System: a collaborative research network to enhance the understanding of wildlife movement. Avian Conservation and Ecology 12(1):8. https://doi.org/10.5751/ACE-00953-120108.

## What this book does not cover {#whatBookCovers}

This book does not cover how to register radio tags with Motus, manage tags and station deployments, or upload raw detections data for processing. Information to guide you through those tasks can be found under the 'resources' tab on the Motus website at <https://motus.org/resources/>.  Please remember to register your tags **prior to deployment**, and enter tag and station metadata online in a timely manner. Please also see <https://motus.org/policy/> to review the Motus collaboration policy and tag registration and fee schedule.

## Prerequisites {#prerequisites}

This book assumes that you have a basic understanding of R. Regardless of whether you are new to R or not, we highly recommend that you become familiar with 'R for Data Science' by Garrett Grolemund and Hadley Wickham (<http://r4ds.had.co.nz/>). Their book covers how to import, visualize, and summarize data in R using the tidyverse collection of R packages <https://www.tidyverse.org/>. It also provides an invaluable framework for organizing your workflow to create clean, reproducible code (<http://r4ds.had.co.nz/workflow-projects.html>). We follow their lead by, wherever possible, using the tidyverse framework throughout this book.

## Sample dataset {#sampleData}

Throughout this book we use a subset of data from the James Bay Shorebird Project to illustrate how to access, manage, and analyze Motus data in R. We recommend that you run through the sample code in each chapter with the sample dataset **before** running through with your own data, because you will undoubtedly need to modify the code we provide in order to deal most effectively with your own data (every situation is different).

The James Bay Shorebird Project conducts monitoring and research on shorebirds staging along the James Bay coast, and is a collaborative effort among the Ontario Ministry of Natural Resources and Forestry, Bird Studies Canada, Trent University, and Environment and Climate Change Canada's Canadian Wildlife Service, in conjunction with a larger conservation initiative involving James Bay First Nations and Nature Canada. The Royal Ontario Museum was a contributing partner until 2016. The goals of the project are to 1) improve the ability to estimate indices of abundance and population trends for shorebird species staging along the western James Bay coast, 2) understand movement patterns and their causes, and 3) identify the relative importance of shorebird staging sites and their habitats. Collectively, this information will aid in the development of conservation measures for Red Knot and other shorebird species through habitat protection like Western Hemisphere Shorebird Reserve Network (WHSRN) designation. More information can be viewed on the James Bay Shorebird Project website at <https://www.jamesbayshorebirdproject.com/>, on Facebook <https://www.facebook.com/jamesbayshorebirdproject/>, or by contacting their project lead:

Christian Friis
Wildlife Biologist
Canadian Wildlife Service Environment and Climate Change Canada / Government of Canada 
christian.friis@canada.ca / Tel: 416.739.4908
 
biologiste de la faune  
Service canadien de la faune Environnement et Changement Climatique Canada / Gouvernement du Canada 
christian.friis@canada.ca / TÃ©l. : 416.739.4908 

## Acknowledgements {#acknowledgements}

Some of the text included in this book was adapted from John Brzustowski's github repository for the Motus R package at: <https://github.com/jbrzusto/motus>.

Motus was conceived as the SensorGnome network by Philip Taylor and John Brzustowski at Acadia University. Initial expansion of the network was supported by a Canada Foundation for Innovation Grant to Western University (Dr. Christopher Guglielmo), The University of Guelph (Dr. Ryan Norris), and Acadia University (Dr. Philip Taylor). The development of the Motus web interface, R package, and accompanying handbook were made possible through a Canarie grant to Bird Studies Canada (<https://www.canarie.ca/>). Motus continues to grow as a program of Bird Studies Canada, through the collaboration of numerous independent researchers, organizations, and individuals. A non-exhaustive list of Motus partners and collaborators can be found at <https://motus.org/data/partners.jsp>. If your organization is not listed, please contact motus@birdscanada.org.

Many people have worked together to bring Motus technology, the web interface, and the R-package together. The core 'Motus Team' includes John Brzustowski, Tara Crewe, Zoe Crysler, Jeremy Hussell, Catherine Jardine, Denis Lepage, Stuart Mackenzie, Paul Morrill, and Philip Taylor. 


<!--chapter:end:01-Introduction.Rmd-->

# Loading R Packages {#loadingPackages}

Two R packages have been developed for Motus users:

1. motus: provides functions to output summary plots, and to transform (add sun rise/sun set times) and analyze Motus data.

2. motusClient: provides functions to download and update detections data and tag and receiver deployment metadata from the Motus server.

Motus **users** can install the latest stable versions of the R packages using the following code. As with all R packages, you only need to install the packages once; after installation, you need to load each package (using library() or require()) each time you open a new R session. 

Please note that some functionalities of the devtools package may require updated versions of R and RStudio. To avoid errors, please ensure you are using the most recent releases of [R](https://www.r-project.org/) and [RStudio](https://www.rstudio.com/products/RStudio/), and update your R packages using update.pacakges() in the R console.

To update your existing packages:

```{r update packages.1, eval = FALSE}

update.packages()                         

```

Begin by installing the required packages, if not already installed. Note that the motusClient package, which is required to access detection data from the Motus server, is a dependency of the broader motus package, i.e., you should only need to run the code to install the motus package, and the motusClient package will be automatically loaded. The code to install the motusClient R package independently is included below, but you should not need to run it.

```{r install packages, eval = FALSE}

install.packages("devtools")
library(devtools)

## install motus for data download, data manipulation, visualization and analysis
install_github("MotusWTS/motus")

## install motusClient for data download
install_github("MotusWTS/motusClient")

library(motus)

```

If you need to update an existing motus or motusClient package, you need to specify "force = TRUE":
```{r update packages.2, eval = FALSE}
## force a re-installation of motus package in case of required updates
install_github("MotusWTS/motus")

## force a re-installation of motusClient package in case of required updates
install_github("MotusWTS/motusClient")

library(motus)

```

Throughout the book, we use tidyverse, which is a collection of R packages for data science, including tidyr, dplyr, ggplot2, and lubridate for managing and manipulating dates. More information on tidyverse can be found at <https://www.tidyverse.org/>, or by browsing (or better still, thoroughly reading) 'R for Data Science' by Garrett Grolemund and Hadley Wickham: <http://r4ds.had.co.nz/>. For mapping we also use the rworldmap, and ggmap packages.  These can be installed from CRAN, as follows:

```{r install tidyverse, eval = FALSE}

install.packages("tidyverse")
library(tidyverse)

install.packages("tidyr")
library(tidyr)

install.packages("rworldmap")
library(rworldmap)

install.packages("ggmap")
library(ggmap)

```

We also install but do not load the plyr package; we use it directly for the handy round_any function, but loading it can cause problems with the dplyr functions:

```{r install plyr, eval = FALSE}

install.packages("plyr")

```

## Internal data processing {#internalProcessing}

As an animal moves within the detection range of a Motus station, radio transmissions, or 'bursts', are detected by antenna(s) and recorded by a receiver. These raw detection data are either uploaded to the Motus database instantaneously via internet connection, or downloaded from the receiver and uploaded to Motus manually. Behind the scenes, various functions read and process the raw detections data to produce the tag detections file that users access using the R package (see Chapter \@ref(accessingData)). While most users will not need to call on the internal data processing functions, a complete list of functions within the Motus server R package can be found on GitHub: <https://github.com/jbrzusto/motusServer>. The code behind each function can be viewed on GitHub, or by typing the following in the R console after loading the R package, replacing 'function.name' with the name of the R function of interest:

```{r function.name, eval = FALSE}

function.name() 

```

In the next chapter we will examine and load some data. 

<!--chapter:end:02-LoadingPackage.Rmd-->

# Accessing and understanding detections data {#accessingData}

```{r fig3, echo = FALSE}

knitr::include_graphics("images/DataStructure.png")

```

<br>

** Before downloading your detection data, please ensure that you have no pending metadata issues through the online [Data Issues page](https://motus.org/data/issues) **

## Database types {#databaseTypes}

There are two types of tag databases:

1. **receiver database**: includes all detections of any registered tags from a single receiver. A receiver database has a name like SG-1234BBBK5678.motus, where the name is the serial number of the receiver.

2. **project database**: includes all detections of your registered tags from across the Motus network. A tag project database has a name like project-123.motus, where the number is the Motus project ID.

These two databases correspond to the basic model of data sharing:

1. you get all detections of anyone's tags by *your* receivers (i.e., one receiver tag database for each receiver you deploy)

2. you get all detections of *your* tags by *anyone's* receivers (i.e., one project tag database for each of your Motus projects)

## Load relevant R packages {#loadPackages}

Before we begin working with data, we need to load the required packages for this chapter. If you have not yet installed these packages (from github and CRAN) then please return to Chapter \@ref(loadingPackages) and do so.

```{r loadPackages, warning = FALSE, message = FALSE}

## required 'motus' package from github
require(motus)

```

## Set system environment

Set the system environment time zone to Greenwich Mean Time (GMT), to ensure that you are always working in GMT. This is a very important step, and should be part of every working session. If you fail to do this, then two problems can arise. Times are stored in the Motus database in GMT, and if you do not keep your environment in GMT, then they can be inadvertently changed during import. Second, if tags have been detected across multiple time zones, then they can also inadvertently be changed.

```{r setTimeZone1}

Sys.setenv(TZ="GMT")

```

## Importing tag detections {#importDetections}

To import tag detections for your project or receiver, you need a numerical project id or character scalar receiver serial number. 

The success of the Motus network is dependent on the timely upload of detection data from receivers, and on the maintenance of accurate and up to date tag and receiver metadata by collaborators. After downloading your data from the Motus server, users are encouraged to check for updated detection data and metadata each time they run an analysis, because collaborators can add detection data and metadata at any time, and these could influence the completeness of your own detections data.

### Download data for a project or receiver for the _first time_

When downloading data from the Motus server for the first time, you must specify new = TRUE and update = TRUE. Unless the directory that you want your data saved in is stated explicitly within the function call, data will be downloaded to the current working directory. 

### User Authentication {#userAuthentication}

Note that the first time you call a function using the Motus R package, you will be asked to enter your motus.org username and password in the R console to authenticate your access to project data. This will only happen once per R session. If you do not have a Motus username and password, you can sign up at <https://motus.org/data/user/new>. Permission to access project data will then be granted by Motus staff or the project principal investigator.

Throughout this book we will use sample data (see \@ref(sampleData)) which has been assigned to project 176.  When accessing this data you will need to login as follows:

user name: motus.sample
password: motus.sample

### Logging out {#logout}

Once you are logged in under one user account, you will not be able to access data from another account.  If you need to logout of the current account to access other data, you can run the code below.

```{r logout, eval = FALSE}

motusLogout()

```

### Downloading detection data {#downloadData}

Let's get started. Note that there are no receivers registered to sample project 176, so the second call (by receiver) will not find any data. You can, however, replace the receiver serial number with one registered to your project if you are logged in under your own credentials (ie. not motus.sample account, see \@ref(logout)). 

<<<<<<< HEAD
Be warned that large datasets can take some time (sometimes a few hours) to download from the Motus server when downloading for the first time ('new = TRUE' in the tagme function call). After the initial download, loading a .motus file into R using 'tagme(proj.num, update = TRUE)' will be near instantaneous. The download process should print its progress on the console; if you are not seeing it, try scrolling down your screen while tagme is running.

In the event that your connection to the Motus server fails prior to the download completing (e.g., due to poor internet connection), use 'tagme(proj.num, update = TRUE)' to continue the download from where it left off, ensuring to specify a directory if it is saved outside the working directory.  


```{r tagme1, eval = FALSE}

getwd()         ## to see the current working directory; use setwd() to change it.
proj.num <- 176 ## 176 for the sample data, or use the number associated with your project here

sql.motus <- tagme(projRecv = proj.num, new = TRUE, update = TRUE)  # for project tag database
sql.motus <- tagme(projRecv = "SG-123BBBK1234", update = TRUE, new = TRUE)  # for receiver tag database

```

If you don't want to use the working directory, specify a directory to create and open a local tag database using "dir = ":

```{r tagme2, eval = FALSE}

sql.motus <- tagme(projRecv = proj.num, new = TRUE, update = TRUE, dir = "./data/") 

```

```{r sql.motus, echo = FALSE}
## hidden function to load sql.motus file into working directory for rest of book to work
sql.motus <- tagme(176, update = FALSE, dir = "./data")
```

The tagme() function will write a copy of your tag database to the working or specified folder, stored as an SQLite file with the extension '.motus'. 

### Update and open a local tag database {#tagmeUpdate}

To open and update a detections database that already exists (has been downloaded previously):

```{r tagme3, eval = FALSE}

sql.motus <- tagme(projRecv = proj.num, new = FALSE, update = TRUE, dir = "./data/") ## use dir = to specify a directory

```

If you are working offline, and want to load an already downloaded database without connecting to the server, use:

```{r tagme3.1, eval = FALSE}

sql.motus <- tagme(projRecv = proj.num, update = FALSE, dir = "./data/")

```

### Check if new data are available {#tellme}

To check if new data are available without downloading the data, you can use the tellme() function, which returns a list with:

- **numHits**: number of new tag detections.
- **numBytes**: approximate uncompressed size of data transfer required, in megabytes.
- **numRuns**: number of runs of new tag detections, where a run is a series of continuous detections for a tag on a given antenna.
- **numBatches**: number of batches of new data. 
- **numGPS**: number of GPS records of new data.

The following assumes that a local copy of the database already exists:

```{r tagme5, eval = FALSE}

tellme(projRecv = proj.num)                    ## If db is in the working directory
tellme(projRecv = proj.num, dir = "./data/")   ## To specify a different directory

```

To check how much data is available for a project but you _do not_ have a database for it, use the 'new' parameter:

```{r tagme6, eval = FALSE}

tellme(projRecv = proj.num, new = TRUE)

```

### Force an update/re-import of tag and receiver deployment metadata {#forceMeta}

Tag and receiver metadata are automatically merged with tag detections when data are downloaded. However, if you want to force a re-import of the metadata when updating a database, you can run:  

```{r tagme7, eval = FALSE}

sql.motus <- tagme(projRecv = proj.num, forceMeta = TRUE)

```

### Import full tag and receiver metadata (#metadata)

When you use tagme() to download or update your .motus file, you are provided with the metadata for:

1. any tags registered to your project which have detections; 
2. tags from other projects which are associated with ambiguous detections (see Chapter \@ref(dataCleaning)) in your data; 
3. receivers that your tags, plus ambiguous tags, were detected on.  

In many instances, you will want access to the full metadata for all tags and receivers across the network, e.g., to determine how many of your deployed tags were not detected, or to plot the location of stations with and without detections. The metadata() function can be used to add the complete Motus metadata to your saved .motus file. The metadata function only needs to be run once, but we suggest that you re-import the metadata occasionally to ensure that you have the most recent and up-to-date information.

Running the metadata function as follows will add the appropriate metadata from across the network (all tags and all receivers) to the 'recvDeps' and 'tagDeps' tables in your .motus file: 

```{r metadata1, eval = FALSE}

metadata(sql.motus) ## access all available tag and receiver metadata for all projects in the network.

```

Alternatively, you can load metadata for a specific project(s) using:

```{r metadata2, eval = FALSE}

metadata(sql.motus, projectIDs = 176) ## access tag and receiver metadata associated with project 176
metadata(sql.motus, projectIDs = c(176, 1)) ## access tag and receiver metadata associated with projects 176 and 1

```


## Data structure {#databaseStructure}

Each tag database is stored as an SQLite ('dplyr::src_sqlite') file with the extension '.motus'. The sqlite format was chosen because:

1. it is flexible, allowing for many data formats.
2. it is accessible from many software platforms (not just R).
3. it is **appendable**: the database can be created and updated on disk without having to read in and resave the entire contents. This will save time and computer memory when searching to see if any new detections are available for your project or receiver.

The .motus file contains a series of interrelated tables where data are stored in a condensed format to save memory. The following tables are included in the .motus file;

1. antDeps: metadata related to antenna deployments, e.g., deployment height, angle, antenna type.
2. batchRuns: metadata for runIDs and associated batchIDs
3. batches: detection data for a given receiver and boot number.
4. filters: metadata related to user created filters associated with the specified receiver.  
5. gps: metadata related to Geographic Positioning System (GPS) position of receiver. 
6. hits: detection data at the level of individual hits.
7. meta: metadata related to the project and datatype (tags vs. receivers) that are included in the .motus file
8. projAmbig: metadata related to what projects have ambiguous tag detections
9. projBatch: metadata for the number of detections contained in each batch
10. projs: metadata related to projects, e.g., project name, principal investigator.
11. recvDeps: metadata related to receiver deployments, e.g., deployment date, location, receiver characteristics.
12. recvs: metadata related to receiver serial number and associated Motus deviceID
13. runs: detection data associated with a run (continuous detections of a unique tag on a given receiver).
14. runsFilters: a list of runIDs associated with user created filters and assigned probabilities.  
15. species: metadata related to species, e.g., unique identifier, scientific name, common name.
16. tagAmbig: metadata related to ambiguous tags, e.g., ambigID and associated motusTagID
17. tagDeps: metadata related to tag deployments, e.g., deployment date, location, and species.
18. tags: metadata related to tags, e.g., unique identifier, tag characteristics (e.g., burst interval).

You can view the list of tables, and variables contained within those tables using the code below:

```{r sqlTables, eval = FALSE}

file.name <- dbConnect(SQLite(), "./data/project-176.motus") ## specify the location and project file name.
dbListTables(file.name) ## get a list of tables in the .motus file specified above.
dbListFields(file.name, "species") ## get a list of variables contained within the "species" table in the .motus file specified above.
```

In addition to these tables, there are also 'virtual' tables or 'views', which have been created through queries that merge data from the various tables into a single convenient 'view' that contains all of the fields you are likely to need. The following views are currently included in each .motus file:

1. allambigs: lists in long-data format each motusTagID (up to 6) associated with each negative ambigID.
2. alltags: provides the full detection data for all tags, and all ambiguous (duplicate) tags,  associated with your project. Ambiguous detections are repeated for each motusTagID represented by each ambigID. 

Because the file is a dplyr::src_sqlite file, all of the dplyr functions can be used to filter and summarize the .motus database, without needing to first save the data as a *flat* file (a typical two-dimensional dataframe). The SQL format is very advantageous when you have a large file -- the queries using SQL will be substantially faster than those done on a flat dataframe. 

Each table and view in the .motus file can be accessed using the tbl() function. 

```{r getTable}

## get the tag deployment metadata table for the current project
tbl.tagDeps <- tbl(sql.motus, "tagDeps")
     
```

The underlying structure of these tables is a list of length 2:

```{r dfStructure, eval = FALSE}

str(tbl.tagDeps)

```

The first part of the list, 'src', is a list that provides details of the SQLiteConnection, including where the database is stored. The second part is a list that includes the underlying table. Thus, the R object 'tagDeps' is a *virtual* table that stores the database structure and information required to connect to the underlying data in the .motus file. As stated above, the advantage of storing the data in this way is that it saves memory when accessing very large databases, and functions within the dplyr package can be used to manipulate and summarize the tables before collecting the results into a typical "flat" format dataframe.

If you want to use familiar functions to get access to components of the underlying data frame, then use the 'collect' function. For example, to look at the names of the variables in tagDeps:

```{r}

tbl.tagDeps %>% 
  collect() %>%
  names() # list the variable names in the table

```

The *virtual* table 'alltags' contains the detection data, along with all metadata variables that most users will ever need from the various underlying .motus tables. It too is accessed using the dplyr tbl() function:  

```{r getAllTagsTable, eval = FALSE}

tbl.alltags <- tbl(sql.motus, "alltags") ## virtual table

```

The following table lists the variables available in the 'alltags' view, a full description of each field is available in \@ref(appendixA)

```{r parameterTable.3, echo = FALSE, eval = FALSE}

tbl.alltags %>% 
      collect() %>%
      names()

```

## Ensure that you have the correct database version {checkVersion}

When you call the tagme function to load the sqlite database, there is a process that will verify that your database has the version matching the most current version of the motus package and store the version in a new table called admInfo. Over time, changes will be made that require adding new tables, views or fields to the database. If you do not have the correct version, some of the examples contained in this book may not work. The following call will check that your database has been updated to the version matching the current version of the motus package. If you do not have the most current version, see \@ref(loadingPackages) for instructions on updating motus and motusClient.  Refer to appendix \@ref(appendixB) if this call returns a warning.


```{r dbVersion, eval = FALSE}
checkVersion(sql.motus)

```

## Convert a SQLITE table to a flat dataframe {#convertToFlat}

To convert the 'alltags' view or other table in the .motus file into a typical 'flat' format, i.e., with every record for each field filled in, use the collect() and as.data.frame() functions. The output can then be further manipulated, or used to generate a RDS file of your data for archiving or export. 

We suggest the following workflow. Prepare a script that downloads/updates your data, filters out the necessary variables, and that does any initial cleaning, and then save the resulting data as an RDS file. We suggest using RDS instead of CSV, because the RDS format preserves the underlying structure of the data (e.g. POSIX times stay as POSIX times). If you want to export your data to another program, then a CSV format might be preferred.  

We caution that producing a flat file using the full suite of fields can use a lot of memory, and can slow R down considerably when dealing with large datasets. For some combinations of data sets and computers, it may be impossible to directly use data frames in R. If that is the case, then this is the point in your workflow where you should carefully consider the information you need from within your data set (for example, how it is aggregated) and simplify it. You can always return to this script, creating a new RDS file with different variables, or aggregated at a different scale.  

We elaborate on this idea in the following sections.  

Make a data frame ...

```{r collect, eval = FALSE}

df.alltags <- tbl.alltags %>% 
                collect() %>% 
                as.data.frame()      ## for all fields in the df (data frame)

```

... and take a quick look at the resulting file. 

```{r quickLook, eval = FALSE}

names(df.alltags)     ## field names
str(df.alltags)       ## Look at the structure of your data fields
head(df.alltags)      ## Look at first 6 rows of your df
summary(df.alltags)   ## summary of each column in your df

```

Note that the format of the time stamp (ts) field is numeric and represents seconds since January 1 1970. We recommend that when you transform your tables into flat dataframes, that you format the time stamp using the lubridate package at that time, e.g.:

```{r collect_TimeStamp, eval = FALSE}

df.alltags <- tbl.alltags %>% 
                collect() %>% 
                as.data.frame() %>%     ## for all fields in the df (data frame)
                mutate(ts = as_datetime(ts, tz = "UTC", origin = "1970-01-01"))

## the tz = "UTC" is not necessary here, provided you have set your system time to UTC/GMT... but it serves as a useful reminder!
```

If you want to load only part of your entire virtual table (e.g. certain fields, certain tags, or all tags from a specified project or species), you can use dplyr funtions to filter the data before collecting into a dataframe. Some examples are below:  

1. To select certain variables:

```{r collect1, eval = FALSE}

## to grab a subset of variables, in this case a unique list of Motus tag IDs at each receiver and antenna.
df.alltagsSub <- select(tbl.alltags, recv, port, motusTagID) %>%
  distinct() %>% 
  collect() %>% 
  as.data.frame() 

```

2. To select certain tag IDs:

```{r collect2, eval = FALSE}
## filter to include only motusTagIDs 16011, 23316
df.alltagsSub <- filter(tbl.alltags, motusTagID %in% c(16011, 23316)) %>% 
                  collect() %>% 
                  as.data.frame() %>%    
                  mutate(ts = as_datetime(ts, tz = "UTC", origin = "1970-01-01"))    

```

3. To select a specified species:

```{r collect3, eval = FALSE}

## filter to only Red Knot (using speciesID)
df.4670 <- filter(tbl.alltags, speciesID == 4670) %>%  
  collect() %>% 
  as.data.frame() %>%    
  mutate(ts = as_datetime(ts, tz = "UTC", origin = "1970-01-01"))  

## filter to only Red Knot (using English name)
df.redKnot <- filter(tbl.alltags, speciesEN == "Red Knot") %>%   
  collect() %>% 
  as.data.frame() %>%    
  mutate(ts = as_datetime(ts, tz = "UTC", origin = "1970-01-01"))    

```

Using dplyr(), your virtual table can also be summarized before converting to a flat file. For example, to find the number of different detections for each tag at each receiver:

```{r collectSum, eval = FALSE}

df.detectSum <- tbl.alltags %>% 
  group_by(motusTagID, recv) %>%
  tally() %>%
  collect() %>%
  as.data.frame() 

```

In later chapter(s) we will show you additional ways of summarizing and working with your data.

## Export your 'flat' dataframe to CSV or RDS file {#exportDetections}

We re-iterated that a good workflow is to create a script that deals with all of your data issues, then saves a dataframe (or workspace) for re-use. If you do this, you can quickly start an analysis or visualization session from a known (and consistent) starting point. We use an RDS file, which preserves all of the associated R data structures (such as time stamps).

```{r createRDS, eval = FALSE, message = FALSE, warning = FALSE}

## save an RDS file

saveRDS(df.alltags, "./data/df.alltags.RDS")  

## or save as CSV file, which does not preserve time stamps, 
## but can be read more easily by other programs.

write_csv(df.alltags, "./data/df.alltags.CSV")

```

## R object naming convention

Throughout this chapter and the rest of the book, we name R objects according to their structure and the source of the data contained in the object. So, SQLite objects will be prefixed with "sql.", virtual table objects will be prefixed with "tbl.", and dataframe objects will be prefixed with "df."; the rest of the name will include the name of the .motus table that the data originates from. Throughout the rest of the book we will be relying on and referencing the naming formats below; please ensure that you are familiar with these before continuing to the next chapter. The following code assumes you have already downloaded the sample data and do not need to update it; if you have not, see section \@ref(dataDownload) for instructions on initial download:

```{r namingConvention, eval = FALSE}

sql.motus <- tagme(176, update = TRUE, dir = "./data")   # SQLite R object, which links to the .motus file
tbl.alltags <- tbl(sql.motus, "alltags")  # virtual table object of the alltags table in the
                                          # sample.motus file
df.alltags <- tbl.alltags %>%
                collect() %>%
                as.data.frame() %>%        # dataframe ("flat") object of the alltags table
                mutate(ts = as_datetime(ts, tz = "UTC", origin = "1970-01-01"))              

```

```{r dataImport, echo = FALSE, eval = TRUE}
## hidden data import so update can be set to FALSE
proj.num= 176
sql.motus <- tagme(176, update = FALSE, dir = "./data")   # SQLite R object, which links to the .motus file
tbl.alltags <- tbl(sql.motus, "alltags")  # virtual table object of the alltags table in the
                                          # sample.motus file
df.alltags <- tbl.alltags %>%
                collect() %>%
                as.data.frame() %>%        # dataframe ("flat") object of the alltags table
                mutate(ts = as_datetime(ts, tz = "UTC", origin = "1970-01-01"))              

```

In the next chapter we will check for missing metadata

<!--chapter:end:03-AccessingData.Rmd-->

# Tag and Receiver Deployments {#deployments}

Before working with your detection data, a first step is to summarize and visualize the metadata for tag and receiver deployments registered to your project. Summarizing and plotting your deployments can be an effective way to find any errors in tag or receiver deployment metadata, which can in turn influence the completeness of the detections data for your project and the projects of others with detections of their own tags on your receivers. 

This chapter is a complement to the online [Data Issues page](https://motus.org/data/issues), which provides each project with a list of metadata issues (missing or outlying values) to be accepted or ignored. As such, please address any and all errors associated with your project on the Data Issues page **before** importing your data through R. This chapter does not provide a full check of your deployment metadata, but will help uncover errors that have been missed by the automatic queries on the Data Issues page.

We use the James Bay Shorebird Project sample dataset throughout this chapter (see Section \@ref(sampleData)). As you run through the code to look at your own deployments, **please fix any errors or omissions in your metadata by signing in to <https://motus.org/>**, and under the 'Manage Data' tab, select either 'Manage Tags' to fix tag deployment metadata or 'Manage Receivers' to fix receiver deployment metadata. It is important to fix metadata errors online, so that errors are fixed at the source and archived on the Motus Server, ensuring all users have access to the correct tag and receiver metadata. Metadata corrected online will automatically be corrected in your detection files. If you have already downloaded your detection data, you can update the existing file to include new metadata and detections (see \@ref(forceMeta), \@ref(tagmeUpdate)).

## Load relevant R packages and set working environment

Before we begin working with data, we need to load the required packages for this chapter. If you have not yet installed these packages (from github and CRAN) then please return to Chapter \@ref(loadingPackages) and do so.

```{r loadPackages.4, eval = FALSE, warning = FALSE, message = FALSE}

library(tidyverse)
library(tidyr)
library(motus)

## Set the system environment time zone to GMT (to ensure that you are always working in GMT)
Sys.setenv(TZ="GMT")

```

## Load .motus file

This chapter assumes that the .motus file has already been downloaded, if you have not done so please return to Chapter \@ref(accessingData) for instructions on how to do so. To update and load the existing file into R, use tagme(), you may have to login as described in the previous chapter with username **and** password "motus.sample"

```{r loadDetections, eval = FALSE}

proj.num <- 176

sql.motus <- tagme(176, update = TRUE, dir = "./data")

```

## Tag Deployments {#tagDeployments}

In your .motus file, when using the tagme function, you are only provided with the metadata for any tags from your project with detections along with metadata for associated ambiguous tags from other projects, and receiver metadata for stations where your tags were detected.  Here we will:

1. download full tag metadata for our project only;  
2. determine how many tags are registered to your project;  
3. determine how many of those registered tags were deployed;  
4. determine location of tag deployments;  
5. determine completeness and accuracy of tag deployment metadata.  

We will run through each of these in sequence.

### 1. Download full project tag metadata 

Incomplete metadata or missing tag registrations can result in missing detection data. We therefore want to assess the completeness of all tags registered to our projects - not just tags for which we have detections. In order to to this we will use the metadata() function for project 176, described in more detail in section \@ref(metadata).

```{r metadata176, eval = FALSE}

metadata(sql.motus, projectIDs = 176)

```

### 2. Number of registered tags

Now that we have complete tag metadata for our project, we can check the number of tags registered by loading the 'tags' table in the .motus file. The 'tags' table contains the metadata of each registered tag, including a unique tagID and information on manufacturer, model, nominal and offset frequency, burst interval, and pulse length. The 'tags' table does not include deployment information. We select the metadata specific to the James Bay Shorebird Project, and ignore tag metadata associated with any duplicate tags belonging to other projects:

```{r importTags, message = FALSE, warning = FALSE}

tbl.tags <- tbl(sql.motus, "tags") 
df.tags <- tbl.tags %>%
                filter(projectID == proj.num) %>%
                collect() %>%
                as.data.frame()

```

The number of rows in the 'df.tags' database is equivalent to the number of tags registered to the James Bay Shorebird Project in the sample dataset (i.e., 18 tags):

```{r nRegisteredTags}

nrow(df.tags) ## number of registered tags in the database

```
You can view the motusTagIDs:

```{r, mtousTagIDs}
unique(df.tags$tagID)
```
If you are missing registered tags, please follow the instructions here: <https://motus.org/tag-registration/>

### 3. Number of registered tags that were deployed

The tag deployment metadata table ('tagDeps') in the .motus file is required to check which registered tags have deployments. This file includes the date, time, species, and location of tag deployment. The database is subset to project '176', and we use the anti_join function to determine which registered tags have (or do not have) corresponding deployment information.

```{r importTagMeta.4, message = FALSE, warning = FALSE}

tbl.tagDeps <- tbl(sql.motus, "tagDeps") 
df.tagDeps <- tbl.tagDeps %>%
                filter(projectID == proj.num) %>%
                collect() %>%
                as.data.frame() %>% # once in dataframe format, can format dates using lubridate
                mutate(tsStart = as_datetime(tsStart, tz = "UTC", origin = "1970-01-01"),
                       tsEnd = as_datetime(tsEnd, tz = "UTC", origin = "1970-01-01")) 

anti_join(df.tags, df.tagDeps, by = "tagID") 

```

In the sample data, there are no registered tags without deployment metadata, which suggests that all tags were deployed. If you have undeployed tags in your own files, please check your records to ensure this is the case; without deployment metadata, detections for registered but 'undeployed' tags will be missing from your detections database.

### 4. Location of tag deployments

Creating a map of your tag deployments can point out any obvious errors in the tag deployment latitude or longitude that weren't captured by the online metadata message center queries.

a. **Load base map files.**

Load base map files from the rworldmap package:

```{r loadMapsRecv1, message = FALSE, warning = FALSE}

## get the lake data; adjust longitude
na.lakes <- map_data(map = "lakes") %>%
  mutate(long = long- 360)

## get the country data; adjust longitude
na.map <- filter(map_data(map="world2"),
                 region %in% c("Canada", "USA")) %>%
  mutate(long = long- 360)
                
## Others countries in the Americas that you may want to plot, depending on your location: "Mexico", "lakes","Belize", "Costa Rica", "Panama", "Guatemala", "Honduras", "Nicaragua", "El Salvador", "Colombia", "Venezuela", "Ecuador", "Peru", "Brazil", "Guyana","Suriname", "Bolivia", "French Guiana", "Jamaica", "Cuba", "Haiti", "Dominican Republic", "The Bahamas", "Turks and Caicos Islands", "Puerto Rico", "British Virgin Islands", "Montserrat", "Dominica", "Saint Lucia", "Barbados", "Grenada", "Trinidad and Tobago", "Chile", "Argentina", "Uruguay"

```

b. **Map the locations of tag deployments.**

Map the location of tag deployments for the sample data: 

```{r mapRecvs1}

## set limits to map based on locations of detections, ensuring they include the deployment locations
xmin <- -100 #min(df.tagDeps$longitude, na.rm = TRUE) - 5
xmax <- max(df.tagDeps$longitude, na.rm = TRUE) + 5
ymin <- min(df.tagDeps$latitude, na.rm = TRUE) - 5
ymax <- max(df.tagDeps$latitude, na.rm = TRUE) + 5
                
## map using ggplot
ggplot(na.lakes, aes(long, lat)) + 
  geom_polygon(
    data = na.map, 
    aes(long, lat, group=group), colour = "grey", fill="grey98") + 
  geom_polygon(
    aes(group = group), colour = "grey", fill = "white") +
  coord_map(projection="mercator", 
            xlim = c(xmin, xmax), 
            ylim = c(ymin, ymax)) +
  xlab("") + ylab("") + 
  theme_bw() + 
  geom_point(data = filter(df.tagDeps, projectID == 176), 
             aes(longitude, latitude), cex = 2, pch = 1, colour = "red")
   
```
If there are any errors in tag deployment location, please correct these online: <https://motus.org/data/>

### 5. Check completeness and accuracy of tag deployment metadata

Required tag metadata includes deployment start date/time, end date/time (if applicable), deployment latitude, deployment longitude, and species. Lack of information on deployment date, time, and location in particular can influence the estimated lifespan of your tag, and therefore whether the tagFinder will 'look' for your tag at the appropriate time(s). It can also increase the potential for ambiguities with duplicate tags in the system. 

a. **Look at range of metadata values**.

As a first step, use summary(df.tagDeps) to get an idea of the range of each variable, and whether any variables have missing (NA) or odd values. The following summarizes a subset of the variables in the df.tagDeps database. There are several things to consider: are the range of start and end dates reasonable for your deployments, or are there obvious errors in the timing of deployments? Is the range in deployment latitude and longitude reasonable? Are the values for species IDs correct?  

```{r summaryTagMeta}

df.tagDeps %>%
      select(tagID, projectID, tsStart, tsEnd, speciesID, latitude, longitude) %>%
      summary()

```

There are no missing start dates (tsStart), and deployment start dates range from `r min(year(df.tagDeps$tsStart))` to `r max(year(df.tagDeps$tsStart))`, which is reasonable for this project.  

The species IDs are numeric, and somewhat meaningless without an ability to assign an actual species name to the numeric ID, which we do next, however there are no missing values. 

b. **Check that species IDs are appropriate for your data**.

The 'species' table in the .motus file associates each numeric species ID with an English, French, and scientific name. We load that table, and subset to the suite of numeric speciesIDs in the tag metadata:

```{r checkSpecies}

## list of species IDs in project 176 metadata
sp.list <- unique(df.tagDeps$speciesID)     ## generate list of speciesIDs in the tag metadata

## Species metadata
tbl.species <- tbl(sql.motus, "species") 
tbl.species %>%
    filter(id %in% sp.list) %>%
    collect() %>%
    as.data.frame()

```

This lists all species that are included in the tag deployment metadata for the project. If there are species that do not make sense, this is likely due to a data entry error when assigning a deployment to a species. You can look for records in your tag metadata that are associated with a particular speciesID using the following code; you would then use the deployID associated with the entry/entries to find and update the deployment record in your project metadata online:

```{r listMetaSpecies}

filter(df.tagDeps, speciesID == 4780)

```

** Don't forget, any metadata corrections need to be made online **

## Check Receiver Metadata {#recvMetadata}


There are two sources of receiver metadata in Motus detection data: receivers registered to your own project, and receivers registered to the projects of others. You can access metadata for all receivers in the network, because negative data (i.e., my tag was *not* detected at station x even though station x was active) is often as important as positive data. It also allows you to map where your tags were detected relative to the distribution of receivers throughout the Motus network.

Receiver metadata errors or omissions that you find in your .motus file can only be fixed for receivers registered to your own project. 

All users are encouraged to enter complete and accurate receiver metadata for the benefit of the entire network. If you anticipate needing specific information on receiver or antenna deployments for stations deployed by others, please consider using the Motus discussion group (<https://motus.org/discussion/>) to request that other registered users record the receiver deployment details you will need; be specific about the exact receiver deployment details you are interested in, and when and where in the network your tags will be deployed and potentially detected. 

In the following steps we will:

1. download full receiver metadata across the network;  
2. determine number of project receiver deployments;
3. determine timing of project receiver deployments;
4. determine location of network-wide and project receiver deployments;
5. determine completeness and accuracy of receiver metadata.

### 1. Download full  receiver metadata 

Later on in this chapter we will want to map all receivers in the network, so we will now load metadata from all projects, as opposed to simply project 176 as we did above. The metadata() function is described in more detail here: \@ref(metadata).

```{r metadataall, eval = FALSE}
metadata(sql.motus)
```

### 2. Number of project receiver deployments

To see which (if any) receiver deployments are registered to your project, import, subset and summarize the receiver deployment data:

```{r projectDeps}

tbl.recvDeps <- tbl(sql.motus, "recvDeps") 
df.projRecvs <- tbl.recvDeps %>%
                filter(projectID == proj.num) %>%
                collect() %>%
                as.data.frame() %>%
                mutate(tsStart = as_datetime(tsStart, tz = "UTC", origin = "1970-01-01"),
                       tsEnd = as_datetime(tsEnd, tz = "UTC", origin = "1970-01-01"))

summary(df.projRecvs)

```

There are `r nrow(df.projRecvs)` receiver deployments registered to the sample project. Four deployments are missing latitude and longitude, and six deployments are missing end dates, which suggests that those receivers are still deployed. 

The following code keeps only variables of interest (by removing those we do not need), and arranges the remaining records by receiver ID, latitude, and start date:

```{r checkRegisteredReceivers}

df.projRecvs %>%
  mutate(dateStart = date(tsStart)) %>% 
  select(-serno,-fixtureType, -macAddress, -tsStart, -tsEnd, -elevation, 
         -projectID, -status, -receiverType, -siteName) %>%
  arrange(deviceID, latitude, dateStart)

```

The number of receiver deployments in the metadata should correspond with the number of field deployments. 

Looking at the 'isMobile' column for the four receiver deployments that are missing latitude and longitude information, it is evident that these are mobile receivers that do not have a fixed position (ie. they have a value of 1). Because they are mobile, coordinates of the deployment aren't expected, and in this case will remain NA. Receiver deployment coordinates for mobile receivers, when present, are meant to represent the starting point for the deployment.

### 3. Timing of project receiver deployments

The timing of deployments can be displayed graphically; horizontal line(s) in the following plot show the time span for each receiver (deviceID) deployment registered to the James Bay Shorebird Project. Note that for the two receivers without deployment end dates, the code assigns an arbitrary end date based on the maximum end date of the other receivers plus one month - without this fix, deployments without end dates do not get displayed. Different deployments of the same receiver should not overlap in time:

```{r projectRecvDeploy, warnings = FALSE, messages = FALSE}

## put data in long format to simplify plotting (or use geom_segment)

df.projRecvs.long <- select(df.projRecvs, deviceID, deployID, tsStart, tsEnd) %>% 
  tidyr::gather(when, ts, c(tsStart, tsEnd)) %>%
  mutate(ts = if_else(is.na(ts), max(ts, na.rm = TRUE) + duration(1, "month"), ts)) ## fake end date 

ggplot(df.projRecvs.long, 
       aes(y = as.factor(deviceID), x = ts, colour = as.factor(deployID))) +
  geom_line(lwd=3) + 
  
  ## instead, center to the right
  geom_text(data=filter(df.projRecvs.long, when == "tsStart"), 
            aes(label=deployID), hjust="left", nudge_y = 0.2, size=3, angle = 45) +
  theme_bw() +
  ylab("Receiver ID") + 
  xlab("Year") + 
  theme(legend.position="none")

```
If you want more detail for a given year (or all years) you can either subset and re-plot, or use the day of year on the x-axis, and facet_wrap by year. 

```{r}
ggplot(df.projRecvs.long, 
       aes(y = as.factor(deviceID), x = yday(ts), colour = as.factor(deployID))) +
  geom_line(lwd=3) + 
  
  ## center labels to the left
  geom_text(data=filter(df.projRecvs.long, when == "tsStart"), 
            aes(label=deployID), hjust="left", nudge_y = 0.4, size=3) +
  theme_bw() +
  ylab("Receiver ID") + 
  xlab("Day of year") + 
  theme(legend.position="none") + 
  facet_grid(year(ts) ~ ., scales="free")
  
```

### 4. Location of receiver deployments

Maps provide better spatial context than simple plots; the following steps plot the location of Motus receivers on a map of North America, with receivers deployed by the sample project displayed in red.

a. **Load all receiver metadata.**
```{r loadRecvDeps}

df.recvDeps <- tbl.recvDeps %>%
                collect() %>%
                as.data.frame() %>%
                mutate(tsStart = as_datetime(tsStart, tz = "UTC", origin = "1970-01-01"),
                       tsEnd = as_datetime(tsEnd, tz = "UTC", origin = "1970-01-01"))

```

b. **Load base map files.**

```{r loadMapsRecv2, message = FALSE, warning = FALSE}

na.lakes <- map_data(map = "lakes")
na.lakes <- mutate(na.lakes, long = long- 360)

## Include all of the Americas to begin

na.map <- subset(map_data(map="world2"), 
                region %in% c("Canada", "USA", "Mexico", "lakes",
                               "Belize", "Costa Rica", "Panama", 
                               "Guatemala", "Honduras", "Nicaragua", 
                               "El Salvador", "Colombia", "Venezuela", "Ecuador", "Peru", "Brazil",
                               "Guyana","Suriname", "Bolivia", "French Guiana", "Jamaica", "Cuba", 
                               "Haiti", "Dominican Republic", "The Bahamas", "Turks and Caicos Islands", 
                               "Puerto Rico", "British Virgin Islands", "Montserrat", "Dominica", "Saint Lucia", 
                               "Barbados", "Grenada", "Trinidad and Tobago", "Chile", "Argentina", 
                               "Uruguay"))

na.map <- mutate(na.map, long = long- 360)

```

c. **Map the location of receivers in the Americas.**

Map showing the location of network-wide receivers (dark grey 'x') and receivers deployed by the James Bay Shorebird Project (project 176; red 'x').

```{r mapRecvs2, message = FALSE, warning = FALSE}

## set limits to map based on locations of detections, ensuring they include the deployment locations
xmin <- min(df.recvDeps$longitude, na.rm = TRUE) - 2
xmax <- -20 # restrict to the Americas (excluding a few points in Europe)
ymin <- min(df.recvDeps$longitude, na.rm = TRUE) - 2
ymax <- max(df.recvDeps$latitude, na.rm = TRUE) + 2
                
## map
ggplot(na.lakes, aes(long, lat))+ 
  geom_polygon(data = na.map, aes(long, lat, group=group), colour = "grey", fill="grey98")+#
  geom_polygon(aes(group = group), colour = "grey", fill = "white")+
  coord_map(projection="mercator", xlim = c(xmin, xmax), ylim = c(ymin, ymax))+
  xlab("") + ylab("") + 
  theme_bw() + 
  geom_point(data = df.recvDeps, aes(longitude, latitude, colour = as.logical(projectID == 176)), 
             cex = 0.8, pch = 4)+
  scale_colour_manual(values = c("grey30", "red"), name = "Project 176 Deployment") 
  

```

c. **Map the location of project specific receivers only.**

Map of project-specific receivers, created by setting the x-axis (longitude) and y-axis (latitude) map limits using the 'df.projRecvs' dataframe created above. Deployments are restricted to those that were active at in 2016.

```{r mapProjRecvs, message = FALSE, warning = FALSE}

## set limits to map based on locations of detections, ensuring they include the deployment locations
xmin <- min(df.projRecvs$longitude, na.rm = TRUE) - 2
xmax <- max(df.projRecvs$longitude, na.rm = TRUE) + 2
ymin <- min(df.projRecvs$latitude, na.rm = TRUE) - 1
ymax <- max(df.projRecvs$latitude, na.rm = TRUE) + 1
                
## map
ggplot(na.lakes, aes(long, lat))+ 
  geom_polygon(data = na.map, aes(long, lat, group=group), colour = "grey", fill="grey98") +
  geom_polygon(aes(group = group), colour = "grey", fill = "white") +
  coord_map(projection="mercator", xlim = c(xmin, xmax), ylim = c(ymin, ymax)) +
#  coord_map(projection="mercator", xlim = c(xmin, xmax), ylim = c(50.154, 52.875)) +
  xlab("") + ylab("") + 
  theme_bw() + 
  geom_point(data = filter(df.projRecvs, 
                            year(tsStart) == 2016, 
                            !is.na(latitude)),  ## remove mobile receivers
             aes(longitude, latitude, colour = as.factor(deviceID)), cex = 2, pch = 1)+
  scale_colour_discrete(name  =  "Receiver ID") 

```

### 5. Completeness and accuracy of receiver metadata

Motus users will be concerned primarily with the completeness of metadata for receiver deployments with detection(s) of their tags, because these can directly influence the interpretation of those detections. For example, missing deployment latitude or longitude will result in an unknown location for the tag detection, and missing information on antenna type and/or orientation can impede the estimation of flight or departure orientation. 

In many cases, however, metadata for receiver deployments *without* tag detections can also be useful, for example to estimate probability of detecting an animal that passes within range of a station.

In this section, the focus is on metadata for receivers registered to a particular project. Depending on your interests, these summaries can be applied to a larger group of receivers, e.g., all receivers with detections or all receivers within certain geographic limits (with or without detections).

a. **Load receiver and antenna metadata**

```{r loadReceiverAntennaMetadata}

## antenna metadata for ALL Motus antenna deployments; 
## to simplify, keep only the variables of interest.
tbl.antDeps <- tbl(sql.motus, "antDeps") 
df.antDeps <- tbl.antDeps %>%
                select(deployID, port, antennaType, bearing, heightMeters) %>%
                collect() %>%
                as.data.frame()

## receiver deployments; select variables of interest
df.recvDeps <- df.recvDeps %>%
                    select(deployID, receiverType, deviceID, name, latitude, longitude, isMobile, tsStart, tsEnd, projectID, elevation) 

df.stationDeps <- left_join(df.recvDeps, df.antDeps, by = "deployID")

```

Subset these to receivers registered to a project:

```{r stationMetaProj}

df.stationDeps <- filter(df.stationDeps, projectID == proj.num)

```

b. **Look at range of metadata values**. 

Use summary() to get a general idea of the distribution of the variables in the data. 

```{r SummaryRecv}

summary(df.stationDeps)

```

There are the 4 deployments with missing latitude and longitude associated with the four deployments of mobile receivers that we saw earlier. 

Elevation is missing from 74 of 91 records, but elevation is not a required field, and can be estimated from other sources, or directly in R (for example, see <https://stackoverflow.com/questions/8973695/conversion-for-latitude-longitude-to-altitude-in-r>). 

Antenna bearing is missing from 18 of 91 records, and height of the antenna(s) is missing for 4 of 91 records.  Subset the records with missing antenna bearing to see if these can be fixed:

```{r antennaBearing}

filter(df.stationDeps, is.na(bearing)) %>%
  select(-elevation, -deviceID, -tsEnd)

```

Receiver deployments with missing antenna bearing(s) are restricted to deployments of omni-directional antennas or mobile receivers, and so the missing values make sense. These records also show that the four records with missing antenna height are also associated with the four mobile receivers, and so again the missing values make sense and do not need to be fixed.  

Remember that any missing metadata needs to be corrected online. Metadata corrected online will automatically be corrected in your detection files. If you have already downloaded your detection data, you can update the existing file to include new metadata and detections (see \@ref(forceMeta), \@ref(tagmeUpdate)).

In the next chapter we will examine our data for false positives, and remove detections of ambiguous tags.

<!--chapter:end:04-ProjectDeployments.Rmd-->

# Data Cleaning {#dataCleaning}

There are three sources of 'error' that can result in tag detections appearing in your database that are incorrect.

First, random radio noise ('static') can be detected and interpreted to be the transmission of a tag. These are called 'false positives'.   

Second, despite our best efforts to avoid it, duplicate tags are sometimes transmitting in the network at the same time. When two tags are deployed at the same time that have the same ID code, burst interval, and nominal transmit frequency, it results in situations where the detections may belong to either tag. If that happens, we must rely on contextual information to separate them (if we can). We term these 'Ambiguous tags'. 

Third, a tag can appear to be present when two tags are transmitting at the same time that by chance produce a signal that looks like a third tag that is not in fact present. Such tags are most common at roosting sites or breeding colonies, where many tags are transmitting simultaneously. We term these 'Aliased tags'. We do not deal explicitly with Aliased tags in this chapter; we are working on a way to globally identify them and eliminate them from the data. We mention them here because you may encounter situations with what appear to be highly plausible detections that don't make biological sense. Please contact us if you think you have some of these Aliased tag detections in your database.

The *goal of this chapter* is to provide you with the tools you need to check your data for false detections, and remove them from your data. We do so by providing example workflows that deal with 'false positives' and 'ambiguous tags' in the following steps: 

1) Run a preliminary filter to remove all detections with runLen of 2. A run is a group of consecutive detections of a tag detected on a single antenna at a single receiver. In general, a detection with a run length of 2 (i.e., 2 bursts) has a high probability of being a false positive detection. With the exception of a few 'quiet' stations with little noise, we generally recommend that you filter out all detections with a run length of 2. However, because you will likely lose some true detections in the process, we also recommend that after a full analysis of your data, you return to these detections and examine them individually, to determine (usually contextually) if they can be considered real.

2) Determine how many of your tag detections may be ambiguous detections. 

3) Provide a workflow for examining individual tags, and determine if runs in those tags are errors. 

4) Filter errors from your data.


## Load required packages

Follow the instructions in Chapter \@ref(loadingPackages) to install the following packages before loading, if they are not already installed.

```{r loadpackages.5, message = FALSE, warning = FALSE}

Sys.setenv(tz="GMT")

library(devtools)
library(motus)
library(tidyverse)
library(lubridate)
library(rworldmap) # for mapping

```

## Load detections data

Recall from \@ref(accessingData) that when accessing the sample database, you will need to input "motus.sample" in the R console as both username and password when prompted by the tagme() user authentication process. This section assumes you have already completed the initial sample data download. 

When accessing the alltags table, we remove some unnecessary variables to reduce the overall size of the data set and make it easier to work with. **This is particularly important for large, unwieldy projects, details on how to view the variables in a tbl, and how to filter and subset prior to collecting data into a dataframe can be found in chapter\@ref(convertToFlat)**. We then create receiver latitude and longitude variables based on the coordinates recorded by the receiver GPS, and where those are not available, infilled with coordinates from the receiver deployment metadata. We use the collect() and as.data.frame() statements to transform the dataframe into a 'flat' file, and then transform all time stamp variables from seconds since January 1 1970 to datetime (POSIXct) format. Finally, we create 'receiver names' from the latitude and longitude variables for those receivers in the database that do not have these values filled in.

```{r importData5, eval = FALSE}

proj.num <- 176

## Load detection data, select variables, create latitude variables, and transform to flat file.
## We also fix up some sites that are missing receiver deployment data, or do not have names
## As more users explore (and fix!) their metadata, these missing values should begin to disappear.
sql.motus <- tagme(proj.num, update = TRUE, dir = "./data/")
tbl.alltags <- tbl(sql.motus, "alltags")

df.alltags <- tbl.alltags %>% 
                mutate(recvLat = if_else((is.na(gpsLat)|gpsLat == 0), recvDeployLat, gpsLat),
                       recvLon = if_else((is.na(gpsLon)|gpsLon == 0), recvDeployLon, gpsLon),
                       recvAlt = if_else(is.na(gpsAlt), recvDeployAlt, gpsAlt)) %>%
                select(-noise, -slop, -burstSlop, -done, -bootnum, -mfgID, -codeSet, -mfg, -nomFreq,
                       -markerNumber, -markerType, -tagDeployComments, -fullID, -deviceID,
                       -recvDeployLat, -recvDeployLon, -recvDeployAlt, -speciesGroup, -gpsLat, 
                       -gpsLon, - recvAlt, - recvSiteName) %>%
                collect() %>%
                as.data.frame() %>%
                mutate(ts = as_datetime(ts),  # work with dates AFTER transforming to flat file
                       tagDeployStart = as_datetime(tagDeployStart),
                       tagDeployEnd = as_datetime(tagDeployEnd), 
                       recvLat = plyr::round_any(recvLat, 0.05), 
                       recvLon = plyr::round_any(recvLon, 0.05),
                       recvDeployName = if_else(is.na(recvDeployName), 
                                                paste(recvLat, recvLon, sep=":"), recvDeployName))

## Note that in the select statement, you can just select the variables you need
## e.g.: select(runID, ts, sig, freqsd, motusTagID, ambigID, runLen, tagProjID, 
##              tagDeployStart, tagDeployEnd, etc.)

```
```{r importData5b, echo = FALSE, eval = TRUE}

proj.num <- 176

## hidden data import so update can be set to FALSE
sql.motus <- tagme(proj.num, update = FALSE, dir = "./data/")
tbl.alltags <- tbl(sql.motus, "alltags")

df.alltags <- tbl.alltags %>% 
                mutate(recvLat = if_else((is.na(gpsLat)|gpsLat == 0), recvDeployLat, gpsLat),
                       recvLon = if_else((is.na(gpsLon)|gpsLon == 0), recvDeployLon, gpsLon),
                       recvAlt = if_else(is.na(gpsAlt), recvDeployAlt, gpsAlt)) %>%
                select(-noise, -slop, -burstSlop, -done, -bootnum, -mfgID, -codeSet, -mfg, -nomFreq,
                       -markerNumber, -markerType, -tagDeployComments, -fullID, -deviceID,
                       -recvDeployLat, -recvDeployLon, -recvDeployAlt, -speciesGroup, -gpsLat, 
                       -gpsLon, - recvAlt, - recvSiteName) %>%
                collect() %>%
                as.data.frame() %>%
                mutate(ts = as_datetime(ts),  # work with dates AFTER transforming to flat file
                       tagDeployStart = as_datetime(tagDeployStart),
                       tagDeployEnd = as_datetime(tagDeployEnd), 
                       recvLat = plyr::round_any(recvLat, 0.05), 
                       recvLon = plyr::round_any(recvLon, 0.05),
                       recvDeployName = if_else(is.na(recvDeployName), 
                                                paste(recvLat, recvLon, sep=":"), recvDeployName))

## Note that in the select statement, you can just select the variables you need
## e.g.: select(runID, ts, sig, freqsd, motusTagID, ambigID, runLen, tagProjID, 
##              tagDeployStart, tagDeployEnd, etc.)

```

## Preliminary data checks

Prior to filtering the data, we do a few summaries and plots of the data.

### Summarize tag detections

First, determine which project tags have detections, and determine how many are of run length 2. There are several reasons why deployed tags might not be detected, including:

1) The tag was not properly activated on deployment. To avoid this, always check that a tag is active using a hand-held receiver before attaching the tag to your study animal and releasing it. 

2) An animal with a properly activated tag might not have passed within range of a receiving station. Study designs that incorporate strategic placement of receivers to meet project goals can improve the probability of a tag being detected.  

3) Missing or incorrect tag deployment metadata in the Motus database can result in the data processing algorithm not 'looking' for your tag at the time the tag was deployed, or at all. Please ensure your tag metadata are entered correctly.  

Using the following code, we see there are detections for 18 tags deployed by the sample project, and that many have run lengths of 2 (TRUE):

```{r ntagsDetections}

df.alltags %>%
  filter(tagProjID == proj.num) %>% # subset to include only tags registered to project
  mutate(rl.gt.2 = runLen == 2) %>%
  group_by(motusTagID, rl.gt.2) %>%
  tally() %>%
  spread(key = rl.gt.2, value=n)

```

Although some of these may be valid detections, we have found it simpler to just remove them from our analysis, and possibly revisit them at a later stage. We therefore filter on runLen (> 2) for most  subsequent operations. We save these in a block to add to our other filters later. 

```{r filterRunLen2}

df.alltags.sub <- filter(df.alltags, 
                         runLen > 2)

df.block.0 <- filter(df.alltags, 
                     runLen == 2) %>% 
  select(motusTagID, runID) %>%
  distinct()

```

An initial view of the data is best achieved by plotting. We will show you later how to plot detections on a map, but we prefer a simpler approach first; plotting detections through time by both latitude and longitude. First however, we should simplify the data. If we don't, we risk trying to plot thousands or millions of points on a plot (which can take a long time). We'll do this by creating a little function here, since we will use this operation again in future steps.

Note that we need to remove about 150 detections, because there is no geographic data associated with the receiver metadata, and so no way to determine the location of those detections. Do a simple check to see if these receivers belong to you, and if so, FIX THE METADATA ONLINE! 

```{r check for missing lat/lon}

filter(df.alltags.sub, is.na(recvLat)) %>%
  select(recvLat, recvLon, recvDeployName, recvDeployID, recv, recvProjID, recvProjName) %>%
  distinct()

```


**Simplify the data for plotting**

```{r fun.getpath, eval = TRUE}

## simplify the data by summarizing by the runID. 
## if you want to summarize at a finer (or coarser) scale, you can also create other groups.  
## The simplest alternative is a rounded timestamp variable; for example by using 
## mutate(ts.h = plyr::round_any(ts, 3600) function call. 
## Other options are to just use date (e.g date = as_date(ts))

## 
fun.getpath <- function(df) 
  {
  df %>%
    filter(tagProjID == proj.num, # keep only tags registered to the sample project
                           !is.na(recvLat) | !(recvLat == 0)) %>% # drops data without lon/lat
    group_by(motusTagID, runID, recvDeployName, ambigID, 
             tagDeployLon, tagDeployLat, recvLat, recvLon) %>%
    summarize(max.runLen = max(runLen), ts.h = mean(ts)) %>% #summarizing by runID to get max run length and mean time stamp
    arrange(motusTagID, ts.h)
  } ## end of function call

df.alltags.path <- fun.getpath(df.alltags.sub)
                    
```

We would initially plot a subset of tags by either latitude or longitude, to get an overview of where there might be issues. Here, to simplify the example, we plot only six tags. We avoid examining the ambiguous tags for now. 

```{r plot1.5}

p <- ggplot(data = filter(df.alltags.path, 
                          motusTagID %in% c(16011, 16035, 16036, 16037, 16038, 16039)), 
            aes(ts.h, recvLat)) 
p + geom_point() + 
  geom_path() + 
  facet_wrap(~motusTagID, scales = "free", ncol=2) + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

```
It is immediately apparent that there may be an issue with some tags showing up around 44 degrees during in the winter, which is possible but unlikely for the sample project's shorebirds. Let's examine these tags in more detail by examining the runs in the data frame that are associated with detections in December and January.

```{r examineRuns}

filter(df.alltags.sub, month(ts) %in% c(12, 1),
       motusTagID %in% c(16036, 16038, 16039)) %>% 
  group_by(recvDeployName, month(ts), runLen) %>%
  summarize(n = length(ts), 
            n.tags = length(unique(motusTagID)))

```

These detections were at sites around the Canadian Maritimes (Sable Island (NS), Grand Manan (NB)) and were run lengths of 3. These are indicators of likely false positives. We'll now start a tally of the particular runs involved, so that we can collate them in to a filter later. 

If you are interested, you can re-run the code above, but on the full data frame (df.alltags) containing run lengths of 2. You will see that there are additional false positive detections at these sites, that are already eliminated by filtering on runLen > 2. These additional detections provide further evidence that these sites experienced some radio noise during these particular months, resulting in some false positive detections.

You may also be interested more generally in exploring which data have only short run lengths. For example, the following code shows the maximum run length at all sites by month (for those runs with runLen > 2).

```{r noisySites}

df.alltags.sub %>%
  mutate(month = month(ts)) %>%
  group_by(recvDeployName, month) %>%
  summarize(max.rl = max(runLen)) %>%
  spread(key=month, value=max.rl)

```

Alternatively, you can produce a list of sites where the maximum run length of detections was never greater than (say) 4, which may sometimes (but not always!) indicate they are simply false detections.

```{r}

df.alltags.sub %>%
  mutate(month = month(ts)) %>%
  group_by(recvDeployName, month) %>%
  summarize(max.rl = max(runLen)) %>%
  filter(max.rl < 5) %>%
  spread(key=month, value=max.rl)

```

It is impossible here to go through every possible issue that you may encounter. Users are strongly encouraged to explore their data fully, and make reasoned decisions on which detections are unlikely or indeterminate. Through the rest of this chapter we will show you how to collect these runs, and apply them to your data prior to analysis. 

To start, we'll create a data frame that contains the motusTagIDs and runIDs for the false positives identified above. 

We will then re-create the plot With the newly filtered data.

```{r createRunsFilter1}

## create the filter
df.block.1 <- filter(df.alltags.sub, month(ts) %in% c(12, 1),
                     motusTagID %in% c(16036, 16038, 16039)) %>%
  select(motusTagID, runID) %>%
  distinct()

## use the function we created earlier to make a new 'path' data frame for plotting
df.alltags.path <- fun.getpath(filter(df.alltags.sub, 
                                      motusTagID %in% c(16011, 16035, 16036, 16037, 16038, 16039), 
                                      !(runID %in% df.block.1$runID)))

p <- ggplot(data = df.alltags.path, aes(ts.h, recvLat)) 
p + geom_point() + 
  geom_path() + 
  facet_wrap(~motusTagID, scales = "free", ncol=2) + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

```

We can see that most of the remaining detections now appear to make more sense, with tags 16035, 16037 and 16039 having been detected during migration, in what appears to be a reasonable latitudinal progression with time, and the other three tags which were not detected very far away from their deployment location. 

The reader is encouraged to explore the rest of the tags within this group, to determine if there are additional false positives. 

## Examining ambiguous detections (#ambigs)

Before we go further, we need to check to see if any tags have ambiguous detections. If there are, we will need to explore them, and create additional filters to remove detections from our database. 

**Are any of your tags associated with ambiguous detections?**

The clarify() function in the motusClient R package provides a summary of ambiguities in the detections data. Each ambigID refers to a selection of detections that could belong to one or more (up to 6) motusTagIDs, which are listed in the id1 to id6 fields:

```{r checkForAmbigs}

clarify(sql.motus)

```

We can see that there are six tags with ambiguous detections within this data set. Detections associated with five of the six ambigIDs could belong to one of two tags, and detections associated with one ambigID (-171) could belong to one of three tags. The fullID fields list the project names associated with the duplicate tags (e.g., "SampleData", "Selva", "Niles"), along with features of the tags (manufacturer tag ID, burst, and transmit frequency).

Let's get a vector of these, and do some plots to see where there may be issues. 

```{r examineAmbigs}

df.ambigTags <- select(df.alltags.sub, ambigID, motusTagID) %>%
  filter(!is.na(ambigID)) %>%
  distinct() 

```

Using our getpath function, we'll create paths and then plot these detections. We'll add some information to the plot, showing where (in time) the tags are actually ambiguous. We can then inspect the overall plots (or portions of them) to determine if we can contextually unambiguously assign a detection of an ambiguous tag to a single deployment.  

```{r plotAmbigs}

df.alltags.path <- fun.getpath(filter(df.alltags.sub, 
                                      motusTagID %in% df.ambigTags$motusTagID, 
                                      tagProjID == proj.num)) %>%
  mutate(Ambiguous = !(is.na(ambigID))) ## create a boolean variable for ambiguous detections

## to put all ambiguous tags from the same project on the same plot together, we need to create
## a new 'ambig tag' variable we call 'newID. 

ambigTags.2 <- filter(df.alltags.sub) %>%
  select(ambigID, motusTagID) %>%
  filter(!is.na(ambigID)) %>%
  distinct() %>%
  group_by(ambigID) %>%
  summarize(newID = paste(unique(ambigID), toString(motusTagID), sep = ": ")) %>%
  left_join(df.ambigTags, by="ambigID")

## and merge that with df.alltags.path
df.alltags.path <- left_join(df.alltags.path, ambigTags.2, by="motusTagID") %>%
  arrange(ts.h)

p <- ggplot(data = df.alltags.path, aes(ts.h, recvLat, group = Ambiguous, colour=Ambiguous)) 
p + geom_point() + 
  geom_path() + 
  facet_wrap(~newID, scales = "free", ncol=2) + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

```

Let's deal with the easy ones first. 

**ambiguous tag -337**
**motusTagID 10811 and 16011:**

```{r lookatambigtag-337}

filter(df.alltags.sub, ambigID == -337) %>%
  group_by(motusTagID, tagDeployStart, tagDeployEnd, tagDeployLat, tagDeployLon) %>%
  tally()

```

We can see from the plot that ambiguous tag -337 is ambiguous only at the beginning of the deployment.

We can see from the summary of the tag deployment data that there were only 4 detections, at the exact latitude of deployment of tag 16011, and just before the non-ambiguous detections of motusTagID 16011. So the issue here is simply that the tail end of the deployment of tag 10811 slightly overlaps with the deployment of tag 16011. We can confidently claim these detections as belonging to motusTagID 16011, and remove the ambiguous detections assigned to the other tag.

We'll create another data frame to keep track of these runs. 

```{r removeambdetectstotag10811}

## we want the detections associated with the motusTagID that we want to 
## ultimately REMOVE from the data frame 
df.block.2 <- filter(df.alltags.sub, 
                     ambigID == -337,
                     motusTagID == 10811) %>% 
  select(motusTagID, runID) %>%
  distinct()


```


**ambiguous tag -134**
**motusTagID 22905 and 23319:**

```{r checkAmbigs}

filter(df.alltags.sub, ambigID == -134) %>%
  group_by(motusTagID, tagDeployStart, tagDeployEnd, tagDeployLat, tagDeployLon, month(ts)) %>%
  tally()

```

Here we have a similar situation, but one that is a bit more complex. Two identical tags were deployed at the same location, shortly after one another. Let's examine a simple plot. 

```{r plotofambigtags-134inOctober}

(filter(df.alltags.sub, motusTagID %in% c(22905, 23319), month(ts) == 10) %>%
  ggplot(aes(ts, sig, group=recvDeployName, colour=recvDeployName)) + 
   geom_point() + 
   xlab("Time") + ylab("Signal strength") +
   facet_grid(recvLon~.))

```

It appears that these are overlapping detections, at two sites in proximity to one another. Additional information from the field researchers may enable us to disentangle them, but it is not clear from the data.

We also examine the non-ambiguous detections of tag -134 that occur in mid-April. These are very early for a Red Knot to be flying through southern Ontario, so should be questioned. 

We see from the following filter that there are two separate runs of length 3 each, separated by 3 days. If we inspect the rest of this batch (that is, if we also look at run lengths of 2 from the original data frame) ... 

```{r}

filter(df.alltags, batchID == 79646) %>% select(runLen, recvDeployName) %>%
  group_by(runLen, recvDeployName) %>%
  tally()

```

... we can see that there are many false positives at this tower around the same time (within the same batch) and so the run lengths of 3 are likely false positives. We will therefore remove all detections of this ambiguous tag from the database. 

```{r}
## we want the detections associated with the motusTagID that we want to 
## ultimately REMOVE from the data frame 

df.block.3 <- filter(df.alltags.sub, 
                     ambigID == -134) %>% 
  select(motusTagID, runID) %>%
  distinct()


```


**ambiguous tag -171**
**motusTagID 22778, 22902 and 22403:**

The ambiguous detections for this tag, which occur in the Great Lakes region, could also belong to motusTagID 22778 from the RBrownAMWO project or motusTagID 24303 from the Neonics project. Let's take a closer look at these detections.

First, find the deployment dates and locations for each tag. 

```{r}

filter(df.alltags, ambigID == -171) %>% 
  filter(!is.na(tagDeployStart)) %>%
  select(motusTagID, tagProjID, start=tagDeployStart, end=tagDeployEnd, 
         lat=tagDeployLat, lon=tagDeployLon, species=speciesEN) %>%
  distinct() %>%
  arrange(start)

```

And plot the ambiguous detections. 

```{r}

df.ambig.171 <- filter(df.alltags.sub, ambigID == -171)

p <- ggplot(data=df.ambig.171, aes(ts, sig, colour=as.factor(port)))
p + geom_point() + geom_smooth(method="loess", se=FALSE) + 
  facet_wrap(as_date(ts) ~ recvDeployName, scales = "free_x") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))


```

We see that there are a large number of ambiguous detections on 10 May 2017 at Old Cut (Long Point, Lake Erie, Canada), consistent with a bird 'hanging around'. These are almost certainly detections of motusTagID '24303' which was deployed at Old Cut on 10 May 2017. Subsequent detections on the 18th of May are near Old Cut (Bird Studies Canada HQ), and then a location to the North of Old Cut (Hagersville, ON). These detections are consistent with a bird departing on migration. Note in particular the pattern in the latter two panels of increasing then decreasing signal strength which indicates a bird is flying through the beam of an antenna.

These detections belong to another project, so we simply remove all detections of that ambiguous tag from our database. 

```{r}
## we want the detections associated with the motusTagID that we want to 
## ultimately REMOVE from the data frame 

df.block.4 <- filter(df.alltags.sub, 
                     ambigID == -171) %>% 
  select(motusTagID, runID) %>%
  distinct()
```


**ambiguous tag -114**
**motusTagID 22897 and 24298:**

Next we look at the ambiguities for ambiguous tag -114.

```{r ambig141}

filter(df.alltags, ambigID == -114) %>% 
  filter(!is.na(tagDeployStart)) %>%
  select(motusTagID, tagProjID, start=tagDeployStart, end=tagDeployEnd, 
         lat=tagDeployLat, lon=tagDeployLon, species=speciesEN) %>%
  distinct() %>%
  arrange(start)

```

We again subset these and plot them. An initial plot suggested that all of the detections are of a migratory flight, so we construct a somewhat different plot from the one above, that emphasizes this behaviour better. 

```{r ambig141b plot 1}

df.ambig.114 <- filter(df.alltags.sub, ambigID == -114)

p <- ggplot(data=df.ambig.114, aes(ts, sig, colour=paste(recvLat, recvLon, recvDeployName, sep=": ")))
p + geom_point() + scale_colour_discrete(name="Lat/Lon and\nStation Name") + 
  facet_wrap(~as_date(ts), scales = "free_x")

```

Notice that the detections are consistent with a migratory departure from the Long Point area (Old Cut Field Station, Lake Erie, Ontario) about a week after the ambiguous tag 24298 was deployed at the same location. This again suggests that these ambiguous detections can be removed from our data because they belong to another project. 

```{r}

df.block.5 <- filter(df.alltags.sub, 
                     ambigID == -114) %>% 
  select(motusTagID, runID) %>%
  distinct()

```


**ambig -106**
**motusTagID 17021 and 17357:**

These two tags pose an interesting problem. There is only a short period of overlap, between mid August 2015 and mid September. One individual is a Grey-cheeked Thrush, tagged in Colombia, the other a White-rumped Sandpiper, associated with the sample project. 

```{r ambig106}

filter(df.alltags, ambigID == -106) %>% 
  filter(!is.na(tagDeployStart)) %>%
  select(motusTagID, tagProjID, start=tagDeployStart, end=tagDeployEnd, 
         lat=tagDeployLat, lon=tagDeployLon, species=speciesEN) %>%
  distinct() %>%
  arrange(start)

```

We plot the ambiguous detections to examine the period of overlap. 

```{r ambig106b}

df.ambig.106 <- filter(df.alltags.sub, ambigID == -106)

p <- ggplot(data=df.ambig.106, aes(ts, sig, colour=paste(recvLat, recvLon, recvDeployName, sep=": ")))
p + geom_point() + scale_colour_discrete(name="Lat/Lon and\nStation Name") + 
  facet_wrap(~as_date(ts), scales = "free_x")

```

Both sets of detections are long run lengths, and look valid (increasing then decreasing signal strength). They are about a day apart, and so it is possible they represent two different birds, or the departure flight of the white-rumped sandpiper from its staging ground. Let's use the siteTrans function (in the motus package, see Chapter \@ref(siteTrans)) to examine the flight from Netitishi to MDR/Seal (in the Gulf of Maine)

```{r}
df.ambig.106 %>% filter(motusTagID == 17021) %>% ## just pick one of the two ambiguous IDs
siteTrans(latCoord = "recvLat", lonCoord = "recvLon") %>%
  ungroup() %>%
  filter(rate < 60) %>% ## remove the simultaneous detections from Seal and MDR
  mutate(total.time = as.numeric(round(seconds_to_period(tot_ts)))) %>%
  select(start=recvDeployName.x, end=recvDeployName.y, date=ts.x, "rate(m/s)" = rate, 
         dist, total.time = total.time, bearing)
```

These detections are >1200 km distant from one another, but the flight speed (17 m/s) is consistent with a white-rumped Sandpiper. Given that the Gray-cheeked Thrush tag was near the end of its expected lifetime, we can reasonably claim these detections for our project, and remove the ambiguous detections associated with motusTagID 17021. 

```{r}
df.block.6 <- filter(df.alltags.sub, 
                     ambigID == -106, 
                     motusTagID == 17021) %>% 
  select(motusTagID, runID) %>%
  distinct()
```


**ambig -56**
**motusTagID 22867 and 23316:**

These two tags were also both deployed by the same project. 

```{r ambig56}

filter(df.alltags, ambigID == -56) %>% 
  filter(!is.na(tagDeployStart)) %>%
  select(motusTagID, tagProjID, start=tagDeployStart, end=tagDeployEnd, 
         lat=tagDeployLat, lon=tagDeployLon, species=speciesEN) %>%
  distinct() %>%
  arrange(start)

```

Tag 23316 was deployed by the James Bay Shorebird Project (Sample Project) about three weeks after tag 22867, which was deployed from a location far to the west. 

```{r ambig56b}

df.ambig.56 <- filter(df.alltags.sub, ambigID == -56) %>%
  mutate(sig = ifelse(sig > 0, sig * -1, sig))

p <- ggplot(data=df.ambig.56, 
            aes(recvLon, ts, colour=paste(recvLat, recvLon, recvDeployName, sep=": ")))
p + geom_point() + scale_colour_discrete(name="Lat/Lon and\nStation Name") 

```
We can see from the plot that a tag is detected consistently near longitude -65, which is near the deployment location for motusTagID 23316 and after it's deployment start date, it was also present at -65 during and after detections far to the west. It's likely all the detections at -65 belong to motusTagID 23316, but it is also clear that anything informative about this ambiguity occurs between about 9-11 October, so let's zoom in on that part of the data set. 

```{r ambig56c}

ts.begin <- ymd_hms("2016-10-06 00:00:00")
ts.end <- ymd_hms("2016-10-12 23:00:00")
p <- ggplot(data=filter(df.ambig.56, 
                        ts > ts.begin, 
                        ts < ts.end),
            aes(ts, recvLon, colour=paste(recvLat, recvLon, recvDeployName, sep=": ")))
p + geom_point() + scale_colour_discrete(name="Lat/Lon and\nStation Name") 

```
We can see that the ambiguous tag was detected consistently at Niapiskau and Grand Ile before and after the period when it was also detected to the north and west (at Washkaugou and Piskwamish) and then to the south (NBNJ, SHNJ, and CONY). We can look at this transition by filtering out the portion of the data not near Niapiskau, and again using the siteTrans function from the motus package. 

```{r ambig56d}

df.56.tmp <- filter(df.ambig.56, !(recvLat == 50.2), motusTagID == 22867) ## the other is a duplicate

siteTrans(df.56.tmp, latCoord = "recvLat", lonCoord = "recvLon") %>%
  ungroup() %>%
  filter(rate < 60) %>% ## get rid of simultaneous detections
  mutate(total.time = as.numeric(round(seconds_to_period(tot_ts)))) %>%
  select(start=recvDeployName.x, end=recvDeployName.y, date=ts.x, "rate(m/s)" = rate, 
         dist, total.time = total.time, bearing)

```

The bird made a 14.5 hour flight between Washkaugou and SHNJ at a rate of 24 m/s, which is plausible. The researchers involved may have other data to support or refute the inference (e.g. an actual sighting of the Red Knot still in Niapiskau after this flight was recorded) but it seems likely that while one tag remained at sites around longitude -65, another tag made the above migratory flights.  We can make another more detailed plot of signal strength to examine these potential migratory flights more closely:

```{r ambig56e}

df.56.tmp <- filter(df.alltags.sub, ambigID == -56, recvLon < -70)

p <- ggplot(data=df.56.tmp, aes(ts, sig, colour=paste(recvLat, recvLon, recvDeployName, sep=": ")))
p + geom_point() + scale_colour_discrete(name="Lat/Lon and\nStation Name") + 
  facet_wrap(~as_date(ts), scales = "free_x")

```

These look like typical fly-by patterns of increasing and then decreasing signal strength.  This, coupled with overall detection patterns and knowledge of the species, leads us to believe that the ambiguous detections can be reasonably divided between the two individuals; one detected consistently around longitude -65 (23316), and the other migrating SW during the same period (22867).

To address this problem, we need to create two filters - one that excludes ambiguous detections of tag 22867, and one that excludes some detections of 23316. In this instance, we can do this most easily by filtering on motusTagID and recvDeployName. 

```{r ambigDetectionsFor56}

## tag 23316 was only ever at "Grand-Ile", "Niapiskau", and tag 22867 was never detected 
## at those sites. So we exclude all detections not at "Grand-Ile", "Niapiskau" for motusTag
## 23316, and do the opposite for tag 22867. 

df.block.7 <- filter(df.alltags.sub, 
                     ambigID == -56, 
                     motusTagID == 23316, 
                     !(recvDeployName %in% c("Grand-Ile", "Niapiskau"))) %>% 
  select(motusTagID, runID) %>%
  distinct()

df.block.8 <- filter(df.alltags.sub, 
                     ambigID == -56, 
                     motusTagID == 22867, 
                     recvDeployName %in% c("Grand-Ile", "Niapiskau")) %>% 
  select(motusTagID, runID) %>%
  distinct()

```

## Filtering the data

### Filter and save to RDS

To filter the data, we can simply join the df.block data frames back to the original data using a left_join(), and filter those from the data:

```{r filterToRDS, message = FALSE, warning = FALSE}

# combine our df.block data frames into a single dataframe, and add probability = 0 for filtered records. 
df.block.all <- bind_rows(df.block.0, df.block.1, df.block.2, df.block.3,
                          df.block.4, df.block.5, df.block.6, df.block.7, df.block.8) %>%
                mutate(probability = 0)

 
df.alltags.sub <- left_join(df.alltags, df.block.all, by = c("runID", "motusTagID")) %>%
  mutate(probability = ifelse(is.na(probability), 1, probability)) %>% # assign a probability of 1 to the records that will not be filtered
  filter(probability > 0)

```

Now save the local data frame as an RDS file, for use in the next chapter. Recall from \@ref(#exportDetections) that the RDS format preserves the R data structure, including time stamps. The other benefit of saving to RDS is that you have the output from a given workflow saved as a flat file, which you can access again with a simple readRDS statement.

```{r saveRDS, eval = FALSE}

saveRDS(df.alltags.sub, file = "./data/dfAlltagsSub.rds")

```

And to read the data in again:

```{r readRDS, eval = FALSE}

df.alltags.sub <- readRDS("./data/dfAlltagsSub.rds")

```

### Save a custom filter in the motus database, and apply it to the data

As an alternative to saving your data as an RDS file, the Motus R package offers functionalities to save your filters directly within your .motus file. Once they are saved in your database, you can do the type of left_join() as above without having to rely on dataframes or an RDS file to store your data. To learn more about the functions available to work with Motus filters, refer to \@ref(#appendixD) for more details. 

```{r saveFilter, eval=FALSE}

# combine our df.block data frames into a single dataframe, and add probability = 0 for filtered records.  
df.block.all <- bind_rows(df.block.0, df.block.1, df.block.2, df.block.3, 
                          df.block.4, df.block.5, df.block.6, df.block.7, df.block.8) %>%
  mutate(probability = 0)

# create a new filter with name filtAmbigFalsePos and populate it with df.block.all
tbl.filter = writeRunsFilter(sql.motus, "filtAmbigFalsePos", df = df.block.all, delete=TRUE)

# obtain a table object where the filtered records from tbl.filter.1 have been removed
tbl.alltags.sub <- left_join(tbl.alltags, tbl.filter, by = c("runID", "motusTagID")) %>%
  mutate(probability = ifelse(is.na(probability), 1, probability)) %>%
  filter(probability > 0)

```


<!--chapter:end:05-DataCleaning.Rmd-->

# Exploring data with the Motus R package {#exploreData}

Once you have clarified any possible ambiguous tags, and removed false positives, you are ready to start analyzing your clean data set. This chapter will walk you through some simple procedures to start working with and visualizing the clean sample data set; you can modify these scripts to work with your own data. For a more in-depth R tutorial we strongly recommend working through R for Data Science by Garrett Grolemund and Hadley Wickham <http://r4ds.had.co.nz/>.

## Load required packages

Follow the instructions in Chapter \@ref(loadingPackages) to install the following packages before loading, if you haven't already done so.

```{r loadpackages.6, message = FALSE, warning = FALSE}

library(motus)
library(tidyverse)

```


```{r setTimeZone2 }

Sys.setenv(TZ="GMT")

```


## Load data

If you followed along with the the previous \@ref(dataCleaning) chapter and are working with cleaned 'df.alltags.sub' file, you can skip this step and move to \@ref(dataSummaries).  

Otherwise, if you saved your data as an RDS file, you can load it using:

```{r importDataRDS, eval = FALSE}

df.alltags.sub <- readRDS("./data/dfAlltagsSub.rds") # change directory to your local directory

```

Or, if you've applied a custom filter to your .motus file, you can load the previously downloaded sample .motus data (see chapter \@ref(accessingData) and clean it now. Currently the main benefit of using the custom filter is that you apply the filter to the .motus file, which allows you more flexibility in applying dplyr functions to manage and filter the data (e.g., you can select different variables to include in the data than we included in the RDS file in Chapter \@ref(#dataCleaning)). Because we are selecting the same variables and filtering the same records, the following gives you the same dataset as the readRDS statement above:

```{r importData, eval = FALSE}

# load the .motus file
proj.num = 176
sql.motus <- tagme(proj.num, update = TRUE, dir = "./data/")
tbl.alltags <- tbl(sql.motus, "alltags")

# obtain a table object of the filter
tbl.filter = getRunsFilters(sql.motus, "filtAmbigFalsePos")

# filter and convert the table into a dataframe, with a few modications
df.alltags.sub <- left_join(tbl.alltags, tbl.filter, by = c("runID", "motusTagID")) %>%
  mutate(probability = ifelse(is.na(probability), 1, probability),
         recvLat = if_else((is.na(gpsLat)|gpsLat == 0), recvDeployLat, gpsLat),
                             recvLon = if_else((is.na(gpsLon)|gpsLon == 0), recvDeployLon, gpsLon),
                             recvAlt = if_else(is.na(gpsAlt), recvDeployAlt, gpsAlt)) %>%
  filter(probability > 0) %>%
  select(-noise, -slop, -burstSlop, -done, -bootnum, -codeSet, -mfg, -nomFreq,
                             -markerNumber, -markerType, -tagDeployComments, -fullID, -deviceID,
                             -recvDeployLat, -recvDeployLon, -recvDeployAlt, -speciesGroup, -gpsLat,
                             -gpsLon, - recvAlt, - recvSiteName) %>%
  collect() %>%
  as.data.frame() %>%
  mutate(ts = as_datetime(ts),  # work with dates AFTER transforming to flat file
         tagDeployStart = as_datetime(tagDeployStart),
         tagDeployEnd = as_datetime(tagDeployEnd))

```
```{r importDataDUPLICATE, echo = FALSE}

# load the .motus file
proj.num = 176
sql.motus <- tagme(proj.num, update = FALSE, dir = "./data/")
tbl.alltags <- tbl(sql.motus, "alltags")

# obtain a table object of the filter
tbl.filter = getRunsFilters(sql.motus, "filtAmbigFalsePos")

# filter and convert the table into a dataframe, with a few modications
df.alltags.sub <- left_join(tbl.alltags, tbl.filter, by = c("runID", "motusTagID")) %>%
  mutate(probability = ifelse(is.na(probability), 1, probability),
         recvLat = if_else((is.na(gpsLat)|gpsLat == 0), recvDeployLat, gpsLat),
                             recvLon = if_else((is.na(gpsLon)|gpsLon == 0), recvDeployLon, gpsLon),
                             recvAlt = if_else(is.na(gpsAlt), recvDeployAlt, gpsAlt)) %>%
  filter(probability > 0) %>%
  select(-noise, -slop, -burstSlop, -done, -bootnum, -codeSet, -mfg, -nomFreq,
                             -markerNumber, -markerType, -tagDeployComments, -fullID, -deviceID,
                             -recvDeployLat, -recvDeployLon, -recvDeployAlt, -speciesGroup, -gpsLat,
                             -gpsLon, - recvAlt, - recvSiteName) %>%
  collect() %>%
  as.data.frame() %>%
  mutate(ts = as_datetime(ts),  # work with dates AFTER transforming to flat file
         tagDeployStart = as_datetime(tagDeployStart),
         tagDeployEnd = as_datetime(tagDeployEnd))

```

**Note that if your project is very large, you may want to convert only a portion of it to the dataframe, to avoid memory issues. Details on filtering the tbl prior to collecting as a dataframe are available in section \@ref(convertToFlat).  Here we do so by adding a filter to the above command, in this case, only creating a dataframe for motusTagID 16047:**

```{r importData2}

# create a subset for a single tag, to keep the dataframe small
df.alltags.16047 <- df.alltags.sub %>%
                      filter(motusTagID == 16047) 
```

## Summarizing your data {#dataSummaries}

Here we will run through some basic commands, starting with the summary() function to view a selection of variables in a data frame:

```{r summaryAllTagsb}

sql.motus %>% 
  tbl("alltags") %>% 
  select(ts, motusTagID, runLen, speciesEN, tagDeployLat, tagDeployLon, 
         recvDeployLat, recvDeployLon) %>% 
  collect() %>%
  summary()

# same summary for the filtered sql data
df.alltags.sub %>% 
  select(ts, motusTagID, runLen, speciesEN, tagDeployLat, tagDeployLon, 
         recvLat, recvLon) %>% 
  summary()
```

The dplyr package allows you to easily summarize data by group, manipulate variables, or create new variables based on your data.  

We can manipulate existing variables or create new ones with dplyr's mutate function, here we'll convert ts to a POSIXct format, then make a new variable for year and day of year (doy).

We'll also remove the set of points with missing receiver latitude and longitudes. These may be useful in some contexts (for example if the approximate location of the receiver is known) but can cause warnings or errors when plotting. 

```{r tagMutate}

df.alltags.sub <- df.alltags.sub %>%
  mutate(ts = as_datetime(ts, tz = "UTC"), ## convert ts to POSIXct format
         year = year(ts), ## extract year from ts
         doy = yday(ts)) %>% ## extract numeric day of year from ts
  filter(!is.na(recvLat))
head(df.alltags.sub)

```

We can also summarize information by group, in this case motusTagID, and apply various functions to these groups such as getting the total number of detections (n) for each tag, the number of receivers each tag was detected on, the first and last detection date, and the total number of days there was at least one detection:

```{r tagSummary}

tagSummary <- df.alltags.sub %>%
  group_by(motusTagID) %>% 
  summarize(nDet = n(),
            nRecv = length(unique(recvDeployName)),
            tsMin = min(ts),
            tsMax = max(ts),
            totDay = length(unique(doy)))

head(tagSummary)

```

We can also group by multiple variables; applying the same function as above but now grouping by motusTagID and recvDeployName, we will get information for each tag detected on each receiver. Since we are grouping by recvDeployName, there will be by default only one recvDeployName in each group, thus the variable nRecv will be 1 for each row. This in not very informative, however we include this to help illustrate how grouping works:

```{r tagRecvSum}

tagRecvSummary <- df.alltags.sub %>%
  group_by(motusTagID, recvDeployName) %>% 
  summarize(nDet = n(),
            nRecv = length(unique(recvDeployName)),
            tsMin = min(ts),
            tsMax = max(ts),
            totDay = length(unique(doy)))

head(tagRecvSummary)

```

## Plotting your data {#dataPlotting}

Plotting your data is a powerful way to visualize broad and fine-scale detection patterns. This section will give you a brief introduction to plotting using ggplot2.  For more in depth information on the uses of ggplot2, we recommend the [Cookbook for R](http://www.cookbook-r.com/Graphs/), and the rstudio [ggplot2 cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf).  

To make coarse-scale plots with large files, we suggest first rounding the detection time to the nearest hour or day so that processing time is faster. Here we round detection times to the nearest hour, then make a basic plot of hourly detections by motusTagID:

```{r hourlyPlot}
df.alltags.sub.2 <- mutate(df.alltags.sub, 
                         hour = as.POSIXct(round(ts, "hour"))) %>% 
  select(motusTagID, port, tagDeployStart, tagDeployLat, tagDeployLon, 
         recvLat, recvLon, recvDeployName, antBearing, speciesEN, year, doy, hour) %>% 
  distinct()

p <- ggplot(data = df.alltags.sub.2, aes(hour, as.factor(motusTagID))) 
p + geom_point() + 
  ylab("MotusTagID") + xlab("Time (rounded to hour)") + 
  theme_bw()
```
Let's focus only on tags deployed in 2016, and we can colour the tags by species:

```{r hourlyPlotSpecies}
p <- ggplot(data = filter(df.alltags.sub.2, year(tagDeployStart) == 2016), 
       aes(hour, as.factor(motusTagID), col = speciesEN)) 
p + geom_point() +
  ylab("MotusTagID") + xlab("Time (rounded to hour)") +
  scale_colour_discrete(name = "Species") +
  theme_bw()
```

We can see how tags moved latitudinally by first ordering by hour, and colouring by motusTagID:

```{r hourlyPlotLat, warnings = FALSE}

df.alltags.sub.2 <- arrange(df.alltags.sub.2, hour)

p <- ggplot(data = filter(df.alltags.sub.2, year(tagDeployStart) == 2016), 
       aes(hour, recvLat, col = as.factor(motusTagID), group = as.factor(motusTagID)))
p +  geom_point() +
  geom_path() +
  theme_bw() + xlab("Time (rounded to hour)") + ylab ("Receiver latitude") +
  scale_colour_discrete(name = "MotusTagID")
```

Now lets look at more detailed plots of signal variation. We use the full df.alltags.sub dataframe so that we can get signal strength for each detection of a specific tag. Let's examine fall 2016 detections of tag 22897 at Niapiskau; we facet the plot by deployment name, ordered by decreasing latitude:


```{r plot22897}

p <- ggplot(filter(df.alltags.sub, 
                   motusTagID == 22897, 
                   recvDeployName == "Niapiskau"), 
       aes(ts, sig)) 
p +  theme_bw() + 
  geom_point() + 
  xlab("Time") + ylab("Signal strength") +
  facet_grid(recvDeployName~.)

```

We use the sunRiseSet function available in the motus R package (see \@ref(sunRiseSet)) to get sunrise and sunset times for all detections. We then zoom in on a certain timeframe and add that information to the above plot by adding a geom_vline() statement to the code, which adds a yellow line for sunrise time, and a blue line for sunset time:

```{r plotSunriset22897}
## add sunrise and sunset times to the dataframe
df.alltags.sub <- sunRiseSet(df.alltags.sub, lat = "recvLat", lon = "recvLon") 

p <- ggplot(filter(df.alltags.sub, motusTagID == 22897 & 
                     ts > ymd("2016-10-11") & ts < ymd("2016-10-17") & 
                     recvDeployName == "Niapiskau"), 
            aes(ts, sig))

p + theme_bw() + 
  geom_point() + 
  xlab("Time of year") + ylab("Signal strength") +
  geom_vline(xintercept = df.alltags.sub$sunrise, col = "orange") + 
  geom_vline(xintercept = df.alltags.sub$sunset, col = "blue")

```
We can see that during this period, the tag was most often detected during the day, suggesting it may be actively foraging in this area during this time.  

The same plots can provide valuable movement information when the receivers are ordered geographically. We do this for motusTagID 16039:
```{r latPlot1}
## We'll first order sitelat by latitude (for plots)
df.alltags.sub <- mutate(df.alltags.sub, 
                         recvDeployName = as.factor(as.character(reorder(recvDeployName, recvLat))))

p <- ggplot(filter(df.alltags.sub, motusTagID == 16039 & 
                     ts < ymd("2015-10-01")), 
       aes(ts, recvDeployName))

p + theme_bw() + 
  geom_point() + 
  xlab("Time of year") + ylab("Receiver name (ordered by latitude)")
```
We zoom in on a section of this plot and look at antenna bearings to see directional movement past stations:

```{r plot2}
p <- ggplot(filter(df.alltags.sub, motusTagID == 16039, 
                   ts > ymd("2015-09-14"), ts < ymd("2015-10-01")), 
            aes(ts, sig, col = as.factor(antBearing))) 
p + theme_bw() + 
  geom_point() + 
  xlab("Time of day") + ylab("Signal strength") +
  scale_color_discrete(name = "Antenna bearing")
  facet_grid(recvDeployName~.)
```
This plot shows the typical flyby pattern of a migrating bird, with signal strength increasing and then decreasing as the tag moves through the beams of the antennas.

## Mapping your data {#mappingData}

To generate maps of tag paths, we will once again use summarized data so we can work with a much smaller database for faster processing. Here we'll summarize detections by day. As we did in Chapter 5, we create a simple function to summarize the data, since we will likely want to do this type of summary over and over again. 

```{r fun.getpath2}

## simplify the data by summarizing by the runID. 
## if you want to summarize at a finer (or coarser) scale, you can also create other groups.  
## The simplest alternative is a rounded timestamp variable; for example by using 
## mutate(ts.h = plyr::round_any(ts, 3600) function call. 
## Other options are to just use date (e.g date = as_date(ts))

## 
fun.getpath <- function(df) 
  {
  df %>%
    filter(tagProjID == proj.num, # keep only tags registered to the sample project
                           !is.na(recvLat) | !(recvLat == 0)) %>% 
    group_by(motusTagID, runID, recvDeployName, ambigID, 
             tagDeployLon, tagDeployLat, recvLat, recvLon) %>%
    summarize(max.runLen = max(runLen), ts.h = mean(ts)) %>%
    arrange(motusTagID, ts.h) %>%
    data.frame()
  } ## end of function call

df.alltags.path <- fun.getpath(df.alltags.sub)
                    
```


```{r plotTagPaths.6}

df.alltags.sub.path <- df.alltags.sub %>%
                    filter(tagProjID == proj.num) %>% # keep to tags registered to the sample project
                    arrange(motusTagID, ts) %>%       # order data by time stamp for each motus tag ID
                    mutate(date = as_date(ts)) %>%    # create date variable
                    group_by(motusTagID, date, recvDeployName, ambigID, tagDeployLon, tagDeployLat, recvLat, recvLon)

df.alltags.path <- fun.getpath(df.alltags.sub.path)
```

### Mapping with Google Maps {#googleMaps}

Mapping with Google Maps can be a fast way to view flight paths and allows you to select from multiple base layers.  
For Google Maps, we'll need to load ggmap and ggplot2 packages; see \@ref(loadingPackages) for instructions on installing the ggmap package if you have not already done so.

```{r installGoogleMapPackages, message = FALSE, warning = FALSE, eval = FALSE}

require(ggmap)

```

The first step is to create a map with a specified map centre, maptype ("terrain", "roadmap", "satellite", or "hybrid"), and level of zoom (integer for zoom 3-21, 3 being continent level, 10 being city-scale).  We then add points for receivers and lines connecting consecutive detections by motusTagID. We can also add points for all receivers that were active during a certain time period if we have already downloaded all metadata.

```{r googleMap, warning = FALSE, fig.width=10, fig.height=10}

gmap <-  get_map(location = c(lon = -75, lat = 40), ## lon/lat to centre map over
                 maptype = "satellite", ## select maptype
                 source = "google",
                 zoom = 4) ## zoom, must be a whole number

## just use the tags that we have examined carefully and filtered (in the previous chapter)
df.tmp <- filter(df.alltags.path, 
                           motusTagID %in% c(16011, 16035, 16036, 16037, 16038, 16039))
df.tmp <- arrange(df.tmp, ts.h) ## arange by hour
df.tmp <- as.data.frame(df.tmp)

p <- ggmap(gmap)
p + geom_point(data=df.tmp, 
               aes(recvLon, recvLat), pch=21, colour = "black", fill = "yellow") +
  geom_path(data=df.tmp, 
            aes(recvLon, recvLat, group=motusTagID, col = as.factor(motusTagID))) +
  theme_bw() + 
  scale_color_discrete(name="MotusTagID")

```
We make the same plot, with additional points for all receivers that were active during a specified time:

```{r googleMapRecvs, warning = FALSE, message = FALSE, fig.width=10, fig.height=10}

## get receiver metadata
tbl.recvDeps <- tbl(sql.motus, "recvDeps")
df.recvDeps <- tbl.recvDeps %>% 
                collect %>% 
                as.data.frame() %>% 
                mutate(tsStart = as_datetime(tsStart, tz = "UTC", origin = "1970-01-01"),
                       tsEnd = as_datetime(tsEnd, tz = "UTC", origin = "1970-01-01"))
## for deployments with no end daets, make an end date a year from now
df.recvDeps$tsEnd <-as.POSIXct(ifelse(is.na(df.recvDeps$tsEnd),
                                       as.POSIXct(format(Sys.time(), "%Y-%m-%d %H:%M:%S")) +
                                lubridate::dyears(1), df.recvDeps$tsEnd), tz = "UTC", origin = "1970-01-01")
## get running intervals for all receiver deployments
siteOp <- with(df.recvDeps, lubridate::interval(tsStart, tsEnd)) ## get running intervals for each deployment
## set the date range you're interested in
dateRange <- lubridate::interval(as.POSIXct("2015-08-01"), as.POSIXct("2016-01-01"))
## create new variable "active" which will be set to TRUE if the receiver was active at some point during your specified date range, and FALSE if not
df.recvDeps$active <- lubridate::int_overlaps(siteOp, dateRange) 

## create map with receivers active during specified date range as red, and receivers with detections as yellow
p <- ggmap(gmap)
p + geom_point(data = subset(df.recvDeps, active == TRUE), ggplot2::aes(longitude, latitude), pch=21, colour = "black", fill = "red") +
  geom_point(data=df.tmp, aes(recvLon, recvLat), pch=21, colour = "black", fill = "yellow") +
  geom_path(data=df.tmp, aes(recvLon, recvLat, group=motusTagID, col = as.factor(motusTagID))) +
  theme_bw() + 
  scale_color_discrete(name="MotusTagID")
```

### Creating simple outline maps {#outlineMaps}

For mapping with outline maps, we'll need to load the rworldmap package; see \@ref(loadingPackages) for instructions on installing the package if you have not already done so.

```{r installMapPackages, message = FALSE, warning = FALSE, eval = FALSE}

require(rworldmap)

```

We first need to load the base maps.

```{r loadMaps.6, message = FALSE, warning = FALSE, eval = FALSE}

## get the lake data; adjust longitude
na.lakes <- map_data(map = "lakes") %>%
  mutate(long = long- 360)

## get the country data; adjust longitude
na.map <- filter(map_data(map="world2"),
                 region %in% c("Canada", "USA", "Mexico", "Belize", "Costa Rica", "Panama", "Guatemala", "Honduras", "Nicaragua", "El Salvador", "Colombia", "Venezuela", "Ecuador", "Peru", "Brazil", "Guyana","Suriname", "Bolivia", "French Guiana", "Jamaica", "Cuba", "Haiti", "Dominican Republic", "The Bahamas", "Turks and Caicos Islands", "Puerto Rico", "British Virgin Islands", "Montserrat", "Dominica", "Saint Lucia", "Barbados", "Grenada", "Trinidad and Tobago", "Chile", "Argentina", "Uruguay", "Paraguay")) %>%
  mutate(long = long- 360)

```

Finally, to map the paths, we set the x-axis and y-axis limits based on the location of receivers with detections. Depending on your data, these might need to be modified to encompass the deployment location of the tags, if tags were not deployed near towers with detections. We then use ggplot to plot the map and tag paths. Here we use the Mercator projection and are colouring the paths by motusTagID, including a point for where the tag was deployed

```{r mapDetections, eval = FALSE}

# set limits to map based on locations of detections, ensuring they include the deployment locations
xmin <- min(df.tmp$recvLon, na.rm = TRUE) - 2
xmax <- max(df.tmp$recvLon, na.rm = TRUE) + 2
ymin <- min(df.tmp$recvLat, na.rm = TRUE) - 2
ymax <- max(df.tmp$recvLat, na.rm = TRUE) + 2
                
# map
ggplot(na.lakes, aes(long, lat))+ 
  geom_polygon(data = na.map, aes(long, lat, group=group), colour = "grey", fill="grey98")+
  geom_polygon(aes(group = group), colour = "grey", fill = "white")+
  coord_map(projection="mercator", xlim = c(xmin, xmax), ylim = c(ymin, ymax))+
  xlab("") + ylab("") + 
  theme_bw()# + 
  geom_path(data = df.tmp, 
           aes(recvLon, recvLat, group = as.factor(motusTagID), colour = as.factor(motusTagID))) #+
  geom_point(data = df.tmp, 
             aes(tagDeployLon, tagDeployLat), colour = "black", shape = 4) +
  scale_colour_discrete("motusTagID") 


```

The functions above provide examples for you how can begin exploring your data and are by no means exhaustive. The next chapter will cover some common errors and troubleshooting you may encounter while trying to download and use the .motus sql files.


<!--chapter:end:06-ExploringData.Rmd-->

# Appendix A - alltags structure {#appendixA}

The following variables are included in each "alltags" view in the SQLite file:

```{r parameterTable.A, echo = FALSE}
param.table <- dplyr::select(read.csv("./data/DatabaseParameters.csv", stringsAsFactors=FALSE), 1:2)
knitr::kable(param.table) 
```

<!--chapter:end:07-AppendixA.Rmd-->

# Appendix B - Troubleshooting {#appendixB}

As a first step, always ensure you are using the latest version of the motus package (see chapter \@ref(checkVersion)), and you have all required packages installed, loaded, and up to date (see Chapter \@ref(loadingPackages).  

While attempting to download data with the motus package, you may encounter errors, many of which are likely due to an interrupted connection - **always ensure you are connected to the internet when using the tagme() function**.  Most issues can be solved by either logging out of the motus package, or by restarting R and resuming the download using tagme(). If errors persist and you are unable to download your data, the server may be temporarily offline. Please contact Motus with any concerns motus@birdscanada.org.

## Logging out of motus {#motusLogout}
```{r motusLogout, eval = FALSE}
motusLogout()
```

## Resume data download {#resumeDownload}

To resume your data download, run tagme() again, but do not include "new = TRUE":

```{r tagmeResume, eval = FALSE}
tagme(project.num, update = TRUE, dir = ...)
```

## Common error messages and solutions:

### I get the message "Auto-disconnecting SQLiteConnection" one or multiple times after using tagme()

If this occurs after data download has finished, this message can be ignored. If it occurs during an active download, the connection will usually be maintained and the download will continue. However if the download stops, simply run tagme() again. If that does not work, we suggest logging out of the motus package or restarting R (see sections \@ref(motusLogout) and \@ref(resumeDownload)).

### I get an "Internal Server Error" message when using tagme(..., update = TRUE)

If you get this message while updating your .motus file, use tagme() again to continue the download.

### I get an "Error: Forbidden" message when using tagme()

This error may occur if you are attempting to download multiple projects simultaneously from the same user account. If you get this error, please logout of the motus package, and try tagme() again (see sections \@ref(motusLogout) and \@ref(resumeDownload)).

### I get an error Object 'xxxx' not found, referring to a table or field name, or some of your examples in the book do not work.  

Be sure to start the steps from the top of the chapter and run them in sequential order. Another possibility is that your .motus database hasn't been updated to support the latest version of the motusClient or the motus package. If the checkVersion function returns a warning, this may indicate that the internal function used to update your database has not been triggered by tagme(). This can happen, for example, if you load the motusClient package without also loading the motus package. Loading the motus package will also load motusClient, so you should only ever need load motus into your R library. 

To ensure that your .motus file is up-to-date with the motus package:

```{r checkVersion, eval = FALSE}
sql.motus <- tagme(project.num, dir= ...)
checkVersion(sql.motus)
```

To correct any warnings, you should follow these steps:

1. download the latest versions of the motusClient and then the motus package (refer to Chapter \@ref(loadingPackages)).
2. terminate and restart your R session.
3. load the motus library using 'require(Motus)' in your R console.
4. load your sqlite file. Look for notes on the console indicating that your database is being updated.
5. check the version again.

```{r checkVersionFix, eval = FALSE}
library(motus)
sql <- tagme(project.num, dir= ...)
checkVersion(sql)
```

Of course, there is always the possibility that the book contains errors! If this does not work, please contact motus@birdscanada.org.

<!--chapter:end:08-AppendixB.Rmd-->

# Appendix C - The Motus R Package {#appendixC}

The motus R package offers functions that work with .motus data to do common computations, summaries and plots. This appendix outlines these functions and provides examples on function use. Many of these functions work with both tbl and data.frame formats, however some require the data to be in sql format as specified below. Detailed instructions on accessing and formatting data are available in Chapter \@ref(accessingData). The examples throughout this chapter work with the sample data which can be accessed and converted to various formats through the following code:

```{r appendixBSample, eval = FALSE}

sql.motus <- tagme(176, new = TRUE, update = TRUE, dir = "./data") # download and access sample data in sql format, username: motus.sample, password: motus.sample

tbl.alltags <- tbl(sql.motus, "alltags") # extract "alltags"" table from sql file "sql.motus"
df.alltags <- tbl.alltags %>% 
  collect() %>% 
  as.data.frame() ## convert the tbl "tbl.alltags" to a data.frame called "df.alltags"

```
```{r appendixBSample2, echo=FALSE, eval = TRUE}

sql.motus <- tagme(176, new = FALSE, update = FALSE, dir = "./data") # download and access sample data in sql format, username: motus.sample, password: motus.sample

tbl.alltags <- tbl(sql.motus, "alltags") # extract "alltags"" table from sql file "sql.motus"
df.alltags <- tbl.alltags %>% 
  collect() %>% 
  as.data.frame() ## convert the tbl "tbl.alltags" to a data.frame called "df.alltags"

```

You can access the function help pages:

```{r functionHelp, eval = FALSE}

??sunRiseSet

```

Or view the underlying function code like this:

```{r functionCode, eval = FALSE}

sunRiseSet

```

## checkVersion {checkVersion.B}
### Description

When you call the tagme() function to load the sqlite database, there is a process that will verify that your database has the version matching the most current version of the motus package and store the version in a new table called admInfo. Over time, changes will be made that require adding new tables, views or fields to the database. The following call will check that your database has been updated to the version matching the current version of the motus package. Refer to the \@ref(Troubleshooting) chapter if this call returns a warning, if you do not have the most recent version, see \@ref(loadingPackages) to update motus and motusClient.
### Dependencies
**sql.motus** an sqlite database of .motus data downloaded using tagme()

### Example
```{r checkVersion.B, eval = FALSE}
checkVersion(sql.motus)
```

## sunRiseSet {#sunRiseSet}
### Description 
Creates and adds a sunrise and sunset variable to a data.frame containing latitude, longitude, and a date/time as POSIXct or numeric.

### Dependencies
**data** can be either a selected table from .motus detection data eg. "alltags", or a data.frame of detection data including at a minimum variables for date/time, latitude, and longitude  
**lat** variable with latitude values, defaults to recvDeployLat  
**lon** variable with longitude values, defaults to recvDeployLon  
**ts** variable with time in UTC as numeric or POSIXct, defaults to ts  

### Example
Add sunrise/sunset variables to the alltags data.frame
```{r sunRiseSet, eval = TRUE}

alltags.df.sun <- sunRiseSet(df.alltags)
head(alltags.df.sun)

```

## plotAllTagsCoord {#plotAllTagsCoor}
### Description
Plot latitude/longitude vs time (UTC rounded to the hour) for each tag using .motus detection data.  Coordinate is by default taken from a receivers GPS latitude recordings.

### Dependencies
**data** a selected table from .motus detection data, eg. "alltags", or a data.frame of detection data including at a minimum variables for date/time, and either latitude or longitude  
**tagsPerPanel** number of tags in each panel of the plot, by default this is 5  
**coordinate** variable name from which to obtain location values, by default it is set to recvDeployLat  
**ts** variable for a date/time object as numeric or POSIXct, defaults to ts  
**recvDepName** variable consisting of receiver deployment name  
**fullID** variable consisting of a tag fullID  
**mfgID** variable consisting of a tags manufacturer ID  

### Example
Plot tags select tags from tbl.alltags with 3 tags per panel
```{r plotAllTagsCoord, eval = TRUE}

plotAllTagsCoord(
  filter(tbl.alltags, motusTagID %in% c(19129, 16011, 17357, 16035, 22897, 23316)), 
  tagsPerPanel = 3)

```

## plotAllTagsSite {#plotAllTagsSite}
### Description
Plot latitude/longitude vs time (UTC rounded to the hour) for each tag using .motus detection data. Coordinate is by default taken from a receivers GPS latitude recordings.

### Dependencies
**data** a selected table from .motus detection data, eg. "alltags", or a data.frame of detection data including at a minimum variables for date/time, and either latitude or longitude  
**tagsPerPanel** number of tags in each panel of the plot, by default this is 5  
**coordinate** variable name from which to obtain location values, by default it is set to recvDeployLat  
**ts** variable for a date/time object as numeric or POSIXct, defaults to ts  
**recvDepName** variable consisting of receiver deployment name  
**fullID** variable consisting of a tag fullID  
**mfgID** variable consisting of a tags manufacturer ID  

### Example
Plot tbl file tbl.alltags using gpsLat and 3 tags per panel for select species Red Knot
```{r, plotAllTagsSite}

plotAllTagsSite(filter(tbl.alltags, speciesEN == "Red Knot"), 
                coordinate = "recvDeployLat", 
                tagsPerPanel = 3)

```

## plotDailySiteSum {#plotDailySiteSum}
### Description
Plots total number of detections across all tags, and total number of tags detected per day for a specified site.  Depends on siteSumDaily function.

### Dependencies
**data** a selected table from .motus data, eg. "alltags", or a data.frame of detection data including at a minimum variables for motusTagID, sig, recvDepName, ts  
**motusTagID** variable consisting of a motus tag ID  
**sig** variable consisting a signal strength variable  
**recvDepName** variable consisting of receiver deployment name  
**ts** variable for a date/time object as numeric or POSIXct, defaults to ts  

### Example
Plot of all tag detections at site Longridge using data.frame df.alltags
```{r, plotDailySiteSum, eval = TRUE}

plotDailySiteSum(df.alltags, recvDeployName = "Longridge")

```

## plotRouteMap {#plotRouteMap}
### Description
Google map of routes of Motus tag detections coloured by motusTagID.  User defines a date range to show points for receivers that were operational at some point during specified date range.
### Dependencies
**data** a .motus sql file  
**maptype** google map type to display, can be: "terrain" , "roadmap", "satellite", or "hybrid"  
**latCentre** latitude to centre map around  
**lonCentre** longitude to centre map around  
**zoom** integer for zoom 3-21, 3 being continent level, 10 being city-scale  
**recvStart** start date for date range of active receivers  
**recvEnd** end date for date range of active receivers  

### Example
Plot routemap of all detection data, with "terrain" maptype, and receivers active between 2016-01-01 and 2017-01-01
```{r, plotRouteMap, eval = TRUE}

plotRouteMap(sql.motus, 
             maptype = "terrain", 
             latCentre = 44, lonCentre = -70, zoom = 5, 
             recvStart = "2016-01-01", recvEnd = "2016-12-31")

```


## plotSite {#plotSite}
### Description

### Dependencies
**data** a selected table from .motus data, eg. "alltags", or a data.frame of detection data including at a minimum variables for ts, antBearing, fullID, recvDepName  
**ts** variable for a date/time object as numeric or POSIXct, defaults to ts  
**antBearing** variable consisting antenna bearing variable  
**fullID** variable consisting of a tag fullID  
**recvDepName** variable consisting of receiver deployment name  

### Example
Plot only detections at a specific site; Piskwamish for data.frame df.alltags
```{r, plotSite, eval = TRUE}

plotSite(filter(df.alltags, recvDeployName == "Piskwamish"))

```

## plotSiteSig {#plotSiteSig}
### Description
Plot signal strength vs time for all tags detected at a specified site, coloured by antenna

### Dependencies
**data** a selected table from .motus data, eg. "alltags", or a data.frame of detection data including at a minimum variables for antBearing, ts, lat, sig, fullID, recvDepName  
**antBearing** variable consisting antenna bearing variable  
**ts** variable for a date/time object as numeric or POSIXct, defaults to ts  
**recvDeployLat** variable consisting of receiver deployment latitude  
**sig** variable consisting a signal strength variable  
**fullID** variable consisting of a tag fullID  
**recvDepName** variable consisting of receiver deployment name  

### Example
Plot select tags for site Piskwamish 
```{r, plotSiteSig, eval = TRUE}

plotSiteSig(filter(df.alltags, motusTagID %in% c(16037, 16039, 16035)), recvDeployName = "Netitishi")

```

## plotTagSig {#plotTagSig}
### Description
Plot signal strength vs time for specified tag, faceted by site (ordered by latitude) and coloured by antenna

### Dependencies
**data** a selected table from .motus data, eg. "alltags", or a data.frame of detection data including at a minimum variables for motusTagID, sig, ts, antBearing, recvDeployLat, fullID, recvDepName  
**motusTagID** variable consisting of a motus tag ID  
**antBearing** variable consisting antenna bearing variable  
**ts** variable for a date/time object as numeric or POSIXct, defaults to ts  
**recvDeployLat** variable consisting of receiver deployment latitude  
**sig** variable consisting a signal strength variable  
**fullID** variable consisting of a tag fullID  
**recvDepName** variable consisting of receiver deployment name  

### Example
Plot signal strength of a specified tag using tbl file tbl.alltags
```{r, plotTagSig, eval = TRUE}

plotTagSig(tbl.alltags, motusTagID = 16035)

```

## simSiteDet {#simSiteDet}
### Description
Creates a data.frame consisting of only detections of tags that are detected at two or more receivers at the same time.
### Dependencies
**data** a selected table from .motus data, eg. "alltags", or a data.frame of detection data including at a minimum variables for ts, motusTagID, recvDepName  
**ts** variable for a date/time object as numeric or POSIXct, defaults to ts  
**motusTagID** variable consisting of a motus tag ID  
**recvDepName** variable consisting of receiver deployment name  

### Example
To get a data.frame called "simSites" of just simultaneous detections from a data.frame df.alltags
```{r, simSiteDet, eval = TRUE}

simSites <- simSiteDet(df.alltags)
head(simSites)

```

## siteSum {#siteSum}
### Description
Creates a summary of the first and last detection at a site, the length of time between first and last detection, the number of tags, and the total number of detections at a site.  Plots total number of detections across all tags, and total number of tags detected at each site.

### Dependencies
**data** a selected table from .motus data, eg. "alltags", or a data.frame of detection data including at a minimum variables for motusTagID, sig, recvDeployLat, recvDepName, and ts  
**motusTagID** variable consisting of a motus tag ID  
**sig** variable consisting a signal strength variable  
**recvDeployLat** variable consisting of receiver deployment latitude  
**recvDepName** variable consisting of receiver deployment name  
**ts** variable for a date/time object as numeric or POSIXct, defaults to ts  
**units** units to display time difference, defaults to "hours", options include "secs", "mins", "hours", "days", "weeks"  

### Example
Create site summaries for select sites with time in minutes
```{r, siteSum, eval = TRUE}

site_summary <- siteSum(filter(df.alltags, 
                               recvDeployName %in% c("Niapiskau", "Netitishi", "Old Cur", "Washkaugou")),
                        units = "mins")
head(site_summary)

```

## siteSumDaily {#siteSumDaily}
### Description
Creates a summary of the first and last daily detection at a site, the length of time between first and last detection, the number of tags, and the total number of detections at a site for each day. Same as siteSum, but daily by site.

### Dependencies
**data** a selected table from .motus data, eg. "alltags", or a data.frame of detection data including at a minimum variables for motusTagID, sig, recvDepName, ts  
**motusTagID** variable consisting of a motus tag ID  
**sig** variable consisting a signal strength variable  
**recvDepName** variable consisting of receiver deployment name  
**ts** variable for a date/time object as numeric or POSIXct, defaults to ts  
**units** units to display time difference, defaults to "hours", options include "secs", "mins", "hours", "days", "weeks"  

### Example
Create site summaries for all sites within detection data with time in minutes using tbl file tbl.alltags
```{r, siteSumDaily, eval = TRUE}

daily_site_summary <- siteSumDaily(tbl.alltags, units = "mins")
head(daily_site_summary)

```

## siteTrans {#siteTrans}
### Description
Creates a data.frame of transitions between sites; detections are ordered by detection time, then "transitions" are identified as the period between the final detection at site x (possible "departure"), and the first detection (possible "arrival") at site y (ordered chronologically). Each row contains the last detection time and lat/lon of site x, first detection time and lat/lon of site y, distance between the site pair, time between detections, rate of movement between detections, and bearing between site pairs.

### Dependencies
**data** a selected table from .motus data, eg. "alltags", or a data.frame of detection data including at a minimum variables for ts, motusTagID, tagDeployID, recvDeployLat, recvDeployLon, recvDepName  
**ts** variable for a date/time object as numeric or POSIXct, defaults to ts  
**motusTagID** variable consisting of a motus tag ID  
**tagDeployID** variable consisting of Motus tag deployment ID  
**recvDeployLat** variable consisting of receiver deployment latitude  
**recvDeployLon** variable consisting of receiver deployment longitude  
**recvDepName** variable consisting of receiver deployment name  

### Example
View site transitions for only tag 16037 from data.frame df.alltags
```{r, siteTrans, eval = TRUE}

transitions <- siteTrans(filter(df.alltags, motusTagID == 16037), 
                         latCoord = "recvDeployLat", lonCoord = "recvDeployLon")
head(transitions)

```

## tagSum {#tagSum}
### Description
Creates a summary for each tag of it's first and last detection time, first and last detection site, length of time between first and last detection,  straight line distance between first and last detection site, rate of movement, and bearing

### Dependencies
**data** a selected table from .motus data, eg. "alltags", or a data.frame of detection dataincluding at a minimum variables for motusTagID, fullID, recvDeployLat, recvDeployLon, recvDepName, ts  
**motusTagID** variable consisting of a motus tag ID  
**fullID** variable consisting of a tag fullID  
**recvDeployLat** variable consisting of receiver deployment latitude  
**recvDeployLon** variable consisting of receiver deployment longitude  
**recvDepName** variable consisting of receiver deployment name  
**ts** variable for a date/time object as numeric or POSIXct, defaults to ts  

### Example
Create tag summary for all tags within detection data using tbl file tbl.alltags
```{r, tagSum, eval = TRUE}

tag_summary <- tagSum(tbl.alltags)
head(tag_summary)

```

## tagSumSite {#tagSumSite}
### Description
Creates a summary for each tag of it's first and last detection time at each site, length of time between first and last detection of each site, and total number of detections at each site.

### Dependencies
**data** a selected table from .motus data, eg. "alltags", or a data.frame of detection data including at a minimum variables for motusTagID, fullID, recvDepName, ts  
**motusTagID** variable consisting of a motus tag ID  
**fullID** variable consisting of a tag fullID  
**recvDepName** variable consisting of receiver deployment name  
**ts** variable for a date/time object as numeric or POSIXct, defaults to ts  

### Example
Create tag summaries for only select tags with time in default hours with data.frame df.alltags
```{r, tagSumSite, eval = TRUE}

tag_site_summary <- tagSumSite(filter(df.alltags, motusTagID %in% c(16047, 16037, 16039)))
head(tag_site_summary)

```

## timeToSunriset {#timeToSunriset}
### Description
Creates and adds variables for time to, and time from sunrise/sunset based on a variable of POSIXct dates/times data.frame must contain latitude, longitude, and a date/time variable

### Dependencies
**data** a selected table from .motus data, eg. "alltags", or a data.frame of detection data including at a minimum variables for date/time, latitude, and longitude  
**lat** variable with latitude values, defaults to recvDeployLat  
**lon** variable with latitude values, defaults to recvDeployLat  
**ts** variable for a date/time object as numeric or POSIXct, defaults to ts  
**units** units to display time difference, defaults to "hours", options include "secs", "mins", "hours", "days", "weeks"  

### Example
Get sunrise and sunset information with units in minutes using tbl file tbl.alltags
```{r, timeToSunriset, eval = TRUE}

sunrise <- timeToSunriset(tbl.alltags, units = "mins")
head(sunrise)

```

<!--chapter:end:09-AppendixC.Rmd-->

# Appendix D - The motusClient Package - Data filtering functions {#appendixD}

The motusClient R package offers functions that can be used to assign probabilities to tag detections, and to filter detections based on those probabilities. For example, as you work through your data to clean false positive and ambiguous detections (see \@ref(dataCleaning)), you may determine that some detections do not belong to your tag(s). Instead of simply using an R script to filter out those detections, you can use these filter functions to create and save a custom filter in your .motus file, which assigns a probability value between 0 and 1 to the runIDs supplied in the filter. 

The data filtering functions in the R package work at the level of a run. A run is a group of consecutive detections of a tag detected on a receiver. In general, a detection with a run length of 2 has a high probability of being a false positive detection. The probabilities associated with each runID can be generated in a number of possible ways, including at the simplest level, generating a list of 0âs and 1âs for records that you would like to exclude or include. Alternatively, you might develop a model that assigns a probability to each runID in your data.

## listRunsFilters {#listRunsFilters}

### Description

Returns a dataframe containing the filterIDs, logins, names, projectIDs and descriptions for a given tag or receiver projectID available in the local database.

## Dependencies

**src** is the SQLite object that you get from loading a .motus file into R, e.g., 'sql.motus' file in \@ref(accessingData). 

## Example

```{r listRunsFilters.C, eval = FALSE}

filt.df <- listRunsFilters(src = sql.motus)

```

## createRunsFilter {#createRunsFilter}

### Description

This function can be used mostly by users to modify properties of existing filters (e.g., filter description or projectID), but it is also being called internally by \@ref(writeRunsFilter) to generate a new filterID. To save the actual filter records, you must rather use  \@ref(writeRunsFilter). The function returns the filterID (integer) in the local database that matches the new or existing filter with the provided filterName. If a filter with the same name already exists, the function generates a warning and returns the ID of the existing filter. 

### Dependencies

**src** is the SQLite object that you get from loading a .motus file into R, e.g., 'sql.motus' file in \@ref(accessingData).   
**filterName** the name you would like to assign to the filter. The function only creates a new filter if the name does not already exist locally.  
**motusProjID** the numeric ID associated with a project, e.g., 176 for the sample data used throughout this book. The function defaults to motusProjID = 'NA' when project ID is not supplied, which is the recommended value for now. The project ID assigned to a filter will mostly be useful for future synchronization of filters with the Motus server. The detection records contained in the filter do not have to be assigned to the projectID assigned to the filter.
**descr** default 'NA'. Optional description of the filter. 
**update** boolean (default = FALSE). If the filter already exists, determines if the properties (e.g. descr are preserved or updated)

### Example

Create a new filter called âmyfilterâ for the sql.motus database which is not attached to a specific project:

```{r createRunsFilter2, eval = FALSE}

createRunsFilter(sql.motus, "myfilter")

# OR add assignment to project

createRunsFilter(sql.motus, "myfilter", motusProjID = 176)

# OR add project and description, possibly updating any previous version called myfilter.

createRunsFilter(sql.motus, "myfilter", motusProjID = 176, descr = "assign probability of 0 to false positives", update=TRUE)

```

## getRunsFilters {#getRunsFilters}

### Description

Returns a sqlite table reference to the  runsFilters records saved in the database (runID, motusTagID, and probability) associated with a specific name (and optionally project) from the local database. For examples on how you can use the returned table to merge with your detection data, refer to \@ref(#saveFilter) in chapter 5.

### Dependencies

**src** is the SQLite object that you get from loading a .motus file into R, e.g., 'sql.motus' file in \@ref(accessingData).   
**filterName** the name you used when you created or saved your filter. Function returns a warning if the filterName doesn't exist.  
**motusProjID** the numeric ID associated with a project, e.g., 176 for the sample data used throughout this book. The function defaults to motusProjID = 'NA' when project ID is not supplied.  

### Example

```{r getRunsFilters, eval = FALSE}

tbl.filt <- getRunsFilters(src = sql.motus, filterName = "myfilter")
tbl.filt2 <- getRunsFilters(sql.motus, "myfilter2")

# filter records from df that are in tbl.filt

df <- left_join(df, tbl.filt, by = c("runID", "motusTagID")) %>%
  mutate(probability = ifelse(is.na(probability), 1, probability)) %>%
  filter(probability > 0)

# you can apply a second filter, tbl.filt2, to the result of the previous filter
df <- left_join(df, tbl.filt2, by = c("runID", "motusTagID")) %>%
  mutate(probability = ifelse(is.na(probability), 1, probability)) %>%
  filter(probability > 0)

```

## writeRunsFilter {#writeRunsFilter}

### Description

Writes to the local database (SQLite file) the content of a dataframe containing runID, motusTagID, and assigned probability. If the filterName provided does not exist, the function will call \@ref(#createRunsFilter) to create one in your database. The default behaviour of the function is that any new records from the dataframe are appended to the existing or new filter called filterName, those that already are present (same runID and motusTagID) are replaced (overwrite=TRUE), but those that are not included in the dataframe are retained in the existing filter table (delete=FALSE). To entirely replace the existing filter values with those of the new dataframe, use delete=TRUE. The function returns a sqlite table reference to the filter, similarly to \@ref(#getRunsFilters).

### Dependencies

**src** is the SQLite object that you get from loading a .motus file into R, e.g., 'sql.motus' file in \@ref(accessingData).   
**filterName** the name of the filter you would like to assign the database to.  
**motusProjID** the numeric ID associated with a project, e.g., 176 for the sample data used throughout this book. Default = 'NA' when project ID is not supplied.  
**df* dataframe which contains the runID (integer), motusTagID (integer), and probability (float) of detections you would like to assign a filter to. MotusTagID should be the actual tag ID, and not the negative ambigID associated with ambiguous detections.
**overwrite** Default = "TRUE". When TRUE, ensures that existing records (same runID and motusTagID) matching the same filterName and runID get replaced in the local database.
**delete** Default = "FALSE". When TRUE, removes all existing filter records associated with the filterName and re-inserts the ones contained in df. This option should be used if df contains the entire set of filters you want to save.

### Examples

```{r writeRunsFilter, eval = FALSE}

# write a dataframe containing filter records (runID, motusTagID and probability) to âmyfilterâ
writeRunsFilter(src = sql.motus, filterName = "myfilter", df = filter.df)

# write a dataframe containing filter records (runID, motusTagID and probability) to âmyfilterâ, overwriting a previous version entirely
writeRunsFilter(src = sql.motus, fileName = "myfilter", df = filter.df, delete = TRUE)

# write a dataframe containing filter records (runID, motusTagID and probability) to "myfilter", but only append new records, leaving previously created ones intact
writeRunsFilter(src = sql.motus, "myfilter", df = filter.df, overwrite = FALSE)

```


<!--chapter:end:10-AppendixD.Rmd-->

